{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ee2a596",
   "metadata": {},
   "source": [
    "# Classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab2a4276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bace': 152,\n",
       " 'bbbp': 198,\n",
       " 'tox21': 778,\n",
       " 'toxcast': 854,\n",
       " 'sider': 136,\n",
       " 'hiv': 4076,\n",
       " 'clintox': 144,\n",
       " 'freesolv': 63,\n",
       " 'lipophilicity': 420,\n",
       " 'esol': 113}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import venn\n",
    "import pandas as pd\n",
    "from data.splitters import scaffold_split\n",
    "from data.loader import MoleculeDataset ##\n",
    "\n",
    "test_len = {}\n",
    "data_root = \"dataset/\"\n",
    "for feature in ['CNN']:\n",
    "    for dt in ['bace', 'bbbp', 'tox21', 'toxcast', 'sider', 'hiv', 'clintox', 'freesolv', 'lipophilicity', 'esol']:\n",
    "        dataset = MoleculeDataset(data_root + dt, dataset=dt, feature=feature)\n",
    "        smiles_list = pd.read_csv(data_root + dt + '/processed/smiles.csv', header=None)[0].tolist()\n",
    "        train_dataset, valid_dataset, test_dataset = scaffold_split(dataset, smiles_list, null_value=0, frac_train=0.8,frac_valid=0.1, frac_test=0.1)\n",
    "        test_len[dt] = len(test_dataset)\n",
    "test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2221fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D-GNN-tuto\n",
      "3D-GNN\n",
      "ChemBERTa\n",
      "CNN\n",
      "FP-MACCS\n",
      "FP-Morgan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "dts = ['bace', 'bbbp', 'tox21', 'toxcast', 'sider', 'hiv']\n",
    "result = {dt: {42: {}, 43: {}, 44: {}, 45: {}, 46: {}} for dt in dts}\n",
    "exps = [fd for fd in Path('experiments').glob(\"*\") if fd.stem != '20250710']\n",
    "for fd in exps:\n",
    "    feature = fd.stem\n",
    "    print(feature)\n",
    "    \n",
    "    files = [f for f in fd.glob('*.csv') if 'result' not in f.stem]\n",
    "    for f in files:\n",
    "        fs = f.stem.split('_')\n",
    "        dt, seed = fs[0], int(fs[3])\n",
    "        \n",
    "        if dt.lower() not in dts:\n",
    "            continue\n",
    "        \n",
    "        data = pd.read_csv(f)\n",
    "        tc = [c for c in data.columns if 'task' in c]\n",
    "        for yt, yp in list(zip(tc[::2], tc[1::2])):\n",
    "            i = yt.split('_')[1]\n",
    "            data[f'correct_{i}'] = (data[yt] == data[yp]).astype(int)\n",
    "            correct = data[data[f'correct_{i}'] == 1]\n",
    "            correct_smiles = set(correct['smiles'].tolist())\n",
    "            \n",
    "            if feature == '2D-GNN-tuto':\n",
    "                feature = '2D-GNN'\n",
    "\n",
    "            result[dt.lower()][seed][f'{feature}_task{i}'] = correct_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2306319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_venn(sts, dt_name, title_name, file_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    \n",
    "    global test_len\n",
    "    \n",
    "    labels = venn.get_labels([sts[0][1], sts[1][1], sts[2][1], sts[3][1], sts[4][1]], fill=['number'])\n",
    "    venn.venn3(labels, names=[sts[0][0], sts[1][0], sts[2][0], sts[3][0], sts[4][0]])\n",
    "\n",
    "    success = sum([int(v) for v in labels.values()])\n",
    "    st1 = sum(map(int, [labels[k] for k in labels.keys() if '1' in k[0]]))\n",
    "    st2 = sum(map(int, [labels[k] for k in labels.keys() if '1' in k[1]]))\n",
    "    st3 = sum(map(int, [labels[k] for k in labels.keys() if '1' in k[2]]))\n",
    "    st4 = sum(map(int, [labels[k] for k in labels.keys() if '1' in k[3]]))\n",
    "    st5 = sum(map(int, [labels[k] for k in labels.keys() if '1' in k[4]]))\n",
    "\n",
    "    fail = test_len[dt_name] - success\n",
    "    memo1_title = '[Test Set]'\n",
    "    memo1 = f'Samples: {test_len[dt_name]}\\nFailed: {fail} ({fail / test_len[dt_name]:.0%})'\n",
    "\n",
    "    memo2_title = '[Oracle Accuracy]'\n",
    "    memo2 = f'{sts[0][0]}: {st1} ({st1 / success:.0%})\\n{sts[1][0]}: {st2} ({st2 / success:.0%})\\n{sts[2][0]}: {st3} ({st3 / success:.0%})\\n{sts[3][0]}: {st4} ({st4 / success:.0%})\\n{sts[4][0]}: {st5} ({st5 / success:.0%})'\n",
    "    plt.text(0, 1.05, memo1_title, fontsize=18)\n",
    "    plt.text(0, 0.99, memo1, fontsize=13)\n",
    "    plt.text(0, 0.94, memo2_title, fontsize=18)\n",
    "    plt.text(0, 0.79, memo2, fontsize=13)\n",
    "    plt.title(f'{title_name}', fontsize=30, fontweight='bold', pad=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d40d042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_venn_v2(lbs, legends, title_name, file_path, test_samples, fail, task_nums):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    \n",
    "    global test_len\n",
    "    venn.venn3(lbs, names=legends)\n",
    "\n",
    "    success = sum([int(v) for v in lbs.values()])\n",
    "    st1 = sum(map(int, [lbs[k] for k in lbs.keys() if '1' in k[0]]))\n",
    "    st2 = sum(map(int, [lbs[k] for k in lbs.keys() if '1' in k[1]]))\n",
    "    st3 = sum(map(int, [lbs[k] for k in lbs.keys() if '1' in k[2]]))\n",
    "    st4 = sum(map(int, [lbs[k] for k in lbs.keys() if '1' in k[3]]))\n",
    "    st5 = sum(map(int, [lbs[k] for k in lbs.keys() if '1' in k[4]]))\n",
    "\n",
    "    memo1_title = '[Test Set]'\n",
    "    memo1 = f'Samples: {test_samples} (num_tasks: {task_nums})\\nFailed: {fail} ({fail / test_samples:.1%})'\n",
    "\n",
    "    memo2_title = '[Oracle Accuracy]'\n",
    "    memo2 = f'All: {round(success)}\\n{legends[0]}: {st1} ({st1 / success:.1%})\\n{legends[1]}: {st2} ({st2 / success:.1%})\\n{legends[2]}: {st3} ({st3 / success:.1%})\\n{legends[3]}: {st4} ({st4 / success:.1%})\\n{legends[4]}: {st5} ({st5 / success:.1%})'\n",
    "    plt.text(0, 1.05, memo1_title, fontsize=16)\n",
    "    plt.text(0, 1.00, memo1, fontsize=12)\n",
    "    plt.text(0, 0.95, memo2_title, fontsize=16)\n",
    "    plt.text(0, 0.80, memo2, fontsize=12)\n",
    "    plt.title(f'{title_name}', fontsize=30, fontweight='bold', pad=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54157da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_venn_v3(lbs, legends, title_name, file_path, test_samples, fail, task_nums):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    \n",
    "    global test_len\n",
    "    venn.venn3(lbs, names=legends)\n",
    "\n",
    "    success = float(f\"{sum([float(v) for v in lbs.values()]):.2f}\")\n",
    "    st1 = float(f\"{sum(map(float, [lbs[k] for k in lbs.keys() if '1' in k[0]])):.2f}\")\n",
    "    st2 = float(f\"{sum(map(float, [lbs[k] for k in lbs.keys() if '1' in k[1]])):.2f}\")\n",
    "    st3 = float(f\"{sum(map(float, [lbs[k] for k in lbs.keys() if '1' in k[2]])):.2f}\")\n",
    "    st4 = float(f\"{sum(map(float, [lbs[k] for k in lbs.keys() if '1' in k[3]])):.2f}\")\n",
    "    st5 = float(f\"{sum(map(float, [lbs[k] for k in lbs.keys() if '1' in k[4]])):.2f}\")\n",
    "\n",
    "    memo1_title = '[Test Set]'\n",
    "    memo1 = f'Samples: {test_samples} (num_tasks: {task_nums})\\nFailed: {fail} ({fail / test_samples:.1%})'\n",
    "\n",
    "    memo2_title = '[Oracle Accuracy]'\n",
    "    memo2 = f'All: {success}\\n{legends[0]}: {st1} ({st1 / success:.1%})\\n{legends[1]}: {st2} ({st2 / success:.1%})\\n{legends[2]}: {st3} ({st3 / success:.1%})\\n{legends[3]}: {st4} ({st4 / success:.1%})\\n{legends[4]}: {st5} ({st5 / success:.1%})'\n",
    "    plt.text(0, 1.05, memo1_title, fontsize=16)\n",
    "    plt.text(0, 1.00, memo1, fontsize=12)\n",
    "    plt.text(0, 0.95, memo2_title, fontsize=16)\n",
    "    plt.text(0, 0.80, memo2, fontsize=12)\n",
    "    plt.title(f'{title_name}', fontsize=30, fontweight='bold', pad=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c6ccaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bace\n",
      "{'00001': 4.93, '00010': 3.29, '00011': 1.79, '00100': 1.05, '00101': 0.45, '00110': 0.45, '00111': 0.75, '01000': 2.99, '01001': 2.69, '01010': 1.35, '01011': 1.64, '01100': 0.45, '01101': 0.6, '01110': 0.45, '01111': 1.49, '10000': 2.99, '10001': 2.54, '10010': 1.35, '10011': 0.9, '10100': 0.3, '10101': 0.75, '10110': 0.9, '10111': 3.29, '11000': 2.39, '11001': 2.24, '11010': 1.35, '11011': 3.74, '11100': 1.2, '11101': 3.44, '11110': 4.04, '11111': 44.25}\n",
      "{'00001': 6.05, '00010': 2.87, '00011': 2.27, '00100': 0.61, '00101': 0.3, '00110': 0.61, '00111': 0.91, '01000': 4.24, '01001': 3.03, '01010': 1.21, '01011': 1.51, '01100': 0.61, '01101': 0.91, '01110': 0.61, '01111': 3.18, '10000': 1.82, '10001': 1.51, '10010': 1.82, '10011': 0.45, '10100': 0.76, '10101': 0.91, '10110': 0.76, '10111': 3.18, '11000': 1.21, '11001': 1.97, '11010': 1.51, '11011': 3.93, '11100': 1.06, '11101': 3.18, '11110': 3.93, '11111': 43.12}\n",
      "Failed: 16.6\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed:\u001b[39m\u001b[38;5;124m'\u001b[39m, fail)\n\u001b[0;32m     61\u001b[0m success_smi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m\u001b[38;5;241m.\u001b[39munion(\u001b[38;5;241m*\u001b[39msuccess_smi)\n\u001b[1;32m---> 62\u001b[0m draw_venn_v3(total_score_v1, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMACCS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1D-CNN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChemBERTa\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2D-GNN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3D-GNN\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVenn/classification/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_MACCS.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtest_samples\u001b[49m, fail, \u001b[38;5;28mlen\u001b[39m(task_num))\n\u001b[0;32m     63\u001b[0m draw_venn_v3(total_score_v2, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMorgan\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1D-CNN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChemBERTa\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2D-GNN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3D-GNN\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVenn/classification/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Morgan.png\u001b[39m\u001b[38;5;124m'\u001b[39m, test_samples, fail, \u001b[38;5;28mlen\u001b[39m(task_num))\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# break\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_samples' is not defined"
     ]
    }
   ],
   "source": [
    "# tox21, toxcast, sider (multi-task)\n",
    "for dt in ['bace', 'bbbp', 'hiv', 'tox21', 'toxcast', 'sider']:\n",
    "    out = Path(f'Venn/classification/')\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(dt)\n",
    "\n",
    "    fail = []\n",
    "    success_smi = []\n",
    "    total_score_v1 = {}\n",
    "    total_score_v2 = {}\n",
    "    for sd in [42, 43, 44, 45, 46]:\n",
    "        pred_data = result[dt][sd]\n",
    "        \n",
    "        task_score_v1 = {}\n",
    "        task_score_v2 = {}\n",
    "        task_num = [c.split('_')[1] for c in pred_data.keys() if 'CNN' in c]\n",
    "        for tn in task_num:\n",
    "            fp_maccs = pred_data[f'FP-MACCS_{tn}']\n",
    "            fp_morgan = pred_data[f'FP-Morgan_{tn}']\n",
    "            cnn = pred_data[f'CNN_{tn}']\n",
    "            chemberta = pred_data[f'ChemBERTa_{tn}']\n",
    "            graph_2d = pred_data[f'2D-GNN_{tn}']\n",
    "            graph_3d = pred_data[f'3D-GNN_{tn}']\n",
    "            \n",
    "            union = set.union(*[fp_maccs, fp_morgan, cnn, chemberta, graph_2d, graph_3d])\n",
    "            success_smi.append(union)\n",
    "            fail.append(test_len[dt] - len(union))\n",
    "            \n",
    "            sts1 = [('MACCS', fp_maccs), ('1D-CNN', cnn), ('ChemBERTa', chemberta), ('2D-GNN', graph_2d), ('3D-GNN', graph_3d)]\n",
    "            labels_v1 = venn.get_labels([sts1[0][1], sts1[1][1], sts1[2][1], sts1[3][1], sts1[4][1]], fill=['number'])\n",
    "            \n",
    "            sts2 = [('Morgan', fp_morgan), ('1D-CNN', cnn), ('ChemBERTa', chemberta), ('2D-GNN', graph_2d), ('3D-GNN', graph_3d)]\n",
    "            labels_v2 = venn.get_labels([sts2[0][1], sts2[1][1], sts2[2][1], sts2[3][1], sts2[4][1]], fill=['number'])\n",
    "            \n",
    "            for k, v in labels_v1.items():\n",
    "                task_score_v1[k] = task_score_v1.get(k, 0) + int(v)\n",
    "                \n",
    "            for k, v in labels_v2.items():\n",
    "                task_score_v2[k] = task_score_v2.get(k, 0) + int(v)\n",
    "        \n",
    "        for k, v in task_score_v1.items():\n",
    "            total_score_v1[k] = total_score_v1.get(k, 0) + v\n",
    "\n",
    "        for k, v in task_score_v2.items():\n",
    "            total_score_v2[k] = total_score_v2.get(k, 0) + v\n",
    "    \n",
    "    total_score_v1 = {k: v / 5 for k, v in total_score_v1.items()}  \n",
    "    v1_sum = sum(total_score_v1.values())\n",
    "    total_score_v1 = {k: float(f\"{(v / v1_sum)*100:.2f}\") for k, v in total_score_v1.items()}\n",
    "    \n",
    "    total_score_v2 = {k: v / 5 for k, v in total_score_v2.items()}\n",
    "    v2_sum = sum(total_score_v2.values())\n",
    "    total_score_v2 = {k: float(f\"{(v / v2_sum)*100:.2f}\") for k, v in total_score_v2.items()}\n",
    "    \n",
    "    print(total_score_v1)    \n",
    "    print(total_score_v2)\n",
    "    fail = float(f\"{sum(fail) / len(fail):.2f}\")\n",
    "    print('Failed:', fail)\n",
    "    \n",
    "    success_smi = set.union(*success_smi)\n",
    "    draw_venn_v3(total_score_v1, ['MACCS', '1D-CNN', 'ChemBERTa', '2D-GNN', '3D-GNN'], f\"{dt.upper()}\", f'Venn/classification/{dt.upper()}_MACCS.png', test_samples, fail, len(task_num))\n",
    "    draw_venn_v3(total_score_v2, ['Morgan', '1D-CNN', 'ChemBERTa', '2D-GNN', '3D-GNN'], f\"{dt.upper()}\", f'Venn/classification/{dt.upper()}_Morgan.png', test_samples, fail, len(task_num))\n",
    "    # break\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4615eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tox21, toxcast, sider (multi-task)\n",
    "for dt in ['bace', 'bbbp', 'hiv', 'tox21', 'toxcast', 'sider']:\n",
    "    out = Path(f'Venn/classification/')\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(dt)\n",
    "\n",
    "    fail = []\n",
    "    success_smi = []\n",
    "    total_score_v1 = {}\n",
    "    total_score_v2 = {}\n",
    "    for sd in [42, 43, 44, 45, 46]:\n",
    "        pred_data = result[dt][sd]\n",
    "        \n",
    "        task_score_v1 = {}\n",
    "        task_score_v2 = {}\n",
    "        task_num = [c.split('_')[1] for c in pred_data.keys() if 'CNN' in c]\n",
    "        for tn in task_num:\n",
    "            fp_maccs = pred_data[f'FP-MACCS_{tn}']\n",
    "            fp_morgan = pred_data[f'FP-Morgan_{tn}']\n",
    "            cnn = pred_data[f'CNN_{tn}']\n",
    "            chemberta = pred_data[f'ChemBERTa_{tn}']\n",
    "            graph_2d = pred_data[f'2D-GNN_{tn}']\n",
    "            graph_3d = pred_data[f'3D-GNN_{tn}']\n",
    "            \n",
    "            union = set.union(*[fp_maccs, fp_morgan, cnn, chemberta, graph_2d, graph_3d])\n",
    "            success_smi.append(union)\n",
    "            fail.append(test_len[dt] - len(union))\n",
    "            \n",
    "            sts1 = [('MACCS', fp_maccs), ('1D-CNN', cnn), ('ChemBERTa', chemberta), ('2D-GNN', graph_2d), ('3D-GNN', graph_3d)]\n",
    "            labels_v1 = venn.get_labels([sts1[0][1], sts1[1][1], sts1[2][1], sts1[3][1], sts1[4][1]], fill=['number'])\n",
    "            \n",
    "            sts2 = [('Morgan', fp_morgan), ('1D-CNN', cnn), ('ChemBERTa', chemberta), ('2D-GNN', graph_2d), ('3D-GNN', graph_3d)]\n",
    "            labels_v2 = venn.get_labels([sts2[0][1], sts2[1][1], sts2[2][1], sts2[3][1], sts2[4][1]], fill=['number'])\n",
    "            \n",
    "            for k, v in labels_v1.items():\n",
    "                task_score_v1[k] = task_score_v1.get(k, 0) + int(v)\n",
    "                \n",
    "            for k, v in labels_v2.items():\n",
    "                task_score_v2[k] = task_score_v2.get(k, 0) + int(v)\n",
    "        \n",
    "        for k, v in task_score_v1.items():\n",
    "            total_score_v1[k] = total_score_v1.get(k, 0) + v\n",
    "\n",
    "        for k, v in task_score_v2.items():\n",
    "            total_score_v2[k] = total_score_v2.get(k, 0) + v\n",
    "    \n",
    "    total_score_v1 = {k: v / 5 for k, v in total_score_v1.items()}  \n",
    "    v1_sum = sum(total_score_v1.values())\n",
    "    total_score_v1 = {k: float(f\"{(v / v1_sum)*100:.2f}\") for k, v in total_score_v1.items()}\n",
    "    \n",
    "    total_score_v2 = {k: v / 5 for k, v in total_score_v2.items()}\n",
    "    v2_sum = sum(total_score_v2.values())\n",
    "    total_score_v2 = {k: float(f\"{(v / v2_sum)*100:.2f}\") for k, v in total_score_v2.items()}\n",
    "    \n",
    "    print(total_score_v1)    \n",
    "    print(total_score_v2)\n",
    "    fail = float(f\"{sum(fail) / len(fail):.2f}\")\n",
    "    print('Failed:', fail)\n",
    "    \n",
    "    success_smi = set.union(*success_smi)\n",
    "    draw_venn_v3(total_score_v1, ['MACCS', '1D-CNN', 'ChemBERTa', '2D-GNN', '3D-GNN'], f\"{dt.upper()}\", f'Venn/classification/{dt.upper()}_MACCS.png', test_samples, fail, len(task_num))\n",
    "    draw_venn_v3(total_score_v2, ['Morgan', '1D-CNN', 'ChemBERTa', '2D-GNN', '3D-GNN'], f\"{dt.upper()}\", f'Venn/classification/{dt.upper()}_Morgan.png', test_samples, fail, len(task_num))\n",
    "    # break\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e390d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 102)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(total_score_v1.values()), sum(total_score_v2.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da60195e",
   "metadata": {},
   "source": [
    "# Regression (corr > heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1537ff19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D-GNN-tuto\n",
      "3D-GNN\n",
      "ChemBERTa\n",
      "CNN\n",
      "FP-MACCS\n",
      "FP-Morgan\n"
     ]
    }
   ],
   "source": [
    "dts = ['esol', 'freesolv', 'lipophilicity']\n",
    "reg_result = {dt: {42: [], 43: [], 44: [], 45: [], 46: []} for dt in dts}\n",
    "exps = [fd for fd in Path('experiments').glob(\"*\") if fd.stem != '20250710']\n",
    "for fd in exps:\n",
    "    feature = fd.stem\n",
    "    print(feature)\n",
    "    \n",
    "    files = [f for f in fd.glob('*.csv') if 'result' not in f.stem]\n",
    "    for f in files:\n",
    "        fs = f.stem.split('_')\n",
    "        dt, seed = fs[0], int(fs[3])\n",
    "        \n",
    "        if dt.lower() not in dts:\n",
    "            continue\n",
    "        \n",
    "        if feature == '2D-GNN-tuto':\n",
    "            feature = '2D-GNN'\n",
    "        elif feature == 'FP-Morgan':\n",
    "            feature = 'Morgan'\n",
    "        elif feature == 'FP-MACCS':\n",
    "            feature = 'MACCS'\n",
    "        elif feature == 'CNN':\n",
    "            feature = '1D-CNN'\n",
    "\n",
    "        data = pd.read_csv(f).rename(columns={'task_0_yt': 'y', 'task_0_yp': feature})\n",
    "        reg_result[dt.lower()][seed].append(data)\n",
    "        \n",
    "        if len(reg_result[dt.lower()][seed]) == 6:\n",
    "            from functools import reduce\n",
    "            reg_result[dt.lower()][seed] = reduce(lambda left, right: pd.merge(left, right, on=['smiles', 'y']), reg_result[dt.lower()][seed])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0cbd105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>y</th>\n",
       "      <th>2D-GNN</th>\n",
       "      <th>3D-GNN</th>\n",
       "      <th>ChemBERTa</th>\n",
       "      <th>1D-CNN</th>\n",
       "      <th>MACCS</th>\n",
       "      <th>Morgan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1cc2ccc3cccc4ccc(c1)c2c34</td>\n",
       "      <td>-6.176</td>\n",
       "      <td>-7.446912</td>\n",
       "      <td>-6.166356</td>\n",
       "      <td>-5.951371</td>\n",
       "      <td>-6.559772</td>\n",
       "      <td>-5.880040</td>\n",
       "      <td>-3.758644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cc1cc(=O)[nH]c(=S)[nH]1</td>\n",
       "      <td>-2.436</td>\n",
       "      <td>-1.049061</td>\n",
       "      <td>-1.472271</td>\n",
       "      <td>-1.555253</td>\n",
       "      <td>-2.005546</td>\n",
       "      <td>-2.544720</td>\n",
       "      <td>-2.474862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>-4.167159</td>\n",
       "      <td>-4.081903</td>\n",
       "      <td>-4.540090</td>\n",
       "      <td>-4.024740</td>\n",
       "      <td>-4.559403</td>\n",
       "      <td>-3.439948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45</td>\n",
       "      <td>-8.699</td>\n",
       "      <td>-8.027051</td>\n",
       "      <td>-7.756307</td>\n",
       "      <td>-6.662787</td>\n",
       "      <td>-7.640496</td>\n",
       "      <td>-5.880040</td>\n",
       "      <td>-7.077580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1=Cc2cccc3cccc1c23</td>\n",
       "      <td>-3.960</td>\n",
       "      <td>-6.744610</td>\n",
       "      <td>-4.339922</td>\n",
       "      <td>-3.898568</td>\n",
       "      <td>-5.621331</td>\n",
       "      <td>-7.344441</td>\n",
       "      <td>-3.118640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl</td>\n",
       "      <td>-6.290</td>\n",
       "      <td>-6.515555</td>\n",
       "      <td>-5.874908</td>\n",
       "      <td>-5.522565</td>\n",
       "      <td>-4.995311</td>\n",
       "      <td>-6.537668</td>\n",
       "      <td>-4.450267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>c1ccsc1</td>\n",
       "      <td>-1.330</td>\n",
       "      <td>-0.521195</td>\n",
       "      <td>-0.873121</td>\n",
       "      <td>-1.007786</td>\n",
       "      <td>-1.002033</td>\n",
       "      <td>-1.320460</td>\n",
       "      <td>-2.255828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43</td>\n",
       "      <td>-7.870</td>\n",
       "      <td>-7.306877</td>\n",
       "      <td>-8.250020</td>\n",
       "      <td>-7.153696</td>\n",
       "      <td>-6.912476</td>\n",
       "      <td>-5.880040</td>\n",
       "      <td>-8.272818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Cc1occc1C(=O)Nc2ccccc2</td>\n",
       "      <td>-3.300</td>\n",
       "      <td>-1.902024</td>\n",
       "      <td>-2.972885</td>\n",
       "      <td>-4.160515</td>\n",
       "      <td>-3.373551</td>\n",
       "      <td>-3.337472</td>\n",
       "      <td>-3.476054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>\n",
       "      <td>-0.770</td>\n",
       "      <td>-0.381649</td>\n",
       "      <td>-1.316217</td>\n",
       "      <td>-3.016346</td>\n",
       "      <td>-3.136367</td>\n",
       "      <td>-1.046856</td>\n",
       "      <td>0.193243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                smiles      y    2D-GNN  \\\n",
       "0                           c1cc2ccc3cccc4ccc(c1)c2c34 -6.176 -7.446912   \n",
       "1                              Cc1cc(=O)[nH]c(=S)[nH]1 -2.436 -1.049061   \n",
       "2           Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4  -2.900 -4.167159   \n",
       "3                     c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45 -8.699 -8.027051   \n",
       "4                                  C1=Cc2cccc3cccc1c23 -3.960 -6.744610   \n",
       "..                                                 ...    ...       ...   \n",
       "108     ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl -6.290 -6.515555   \n",
       "109                                            c1ccsc1 -1.330 -0.521195   \n",
       "110                 c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43 -7.870 -7.306877   \n",
       "111                             Cc1occc1C(=O)Nc2ccccc2 -3.300 -1.902024   \n",
       "112  OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)... -0.770 -0.381649   \n",
       "\n",
       "       3D-GNN  ChemBERTa    1D-CNN     MACCS    Morgan  \n",
       "0   -6.166356  -5.951371 -6.559772 -5.880040 -3.758644  \n",
       "1   -1.472271  -1.555253 -2.005546 -2.544720 -2.474862  \n",
       "2   -4.081903  -4.540090 -4.024740 -4.559403 -3.439948  \n",
       "3   -7.756307  -6.662787 -7.640496 -5.880040 -7.077580  \n",
       "4   -4.339922  -3.898568 -5.621331 -7.344441 -3.118640  \n",
       "..        ...        ...       ...       ...       ...  \n",
       "108 -5.874908  -5.522565 -4.995311 -6.537668 -4.450267  \n",
       "109 -0.873121  -1.007786 -1.002033 -1.320460 -2.255828  \n",
       "110 -8.250020  -7.153696 -6.912476 -5.880040 -8.272818  \n",
       "111 -2.972885  -4.160515 -3.373551 -3.337472 -3.476054  \n",
       "112 -1.316217  -3.016346 -3.136367 -1.046856  0.193243  \n",
       "\n",
       "[113 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_avg = {}\n",
    "for dt in ['esol', 'freesolv', 'lipophilicity']:\n",
    "    dfs = [reg_result[dt][sd] for sd in [42, 43, 44, 45, 46]]\n",
    "    mean_values = sum(df[dfs[0].columns[2:]] for df in dfs) / len(dfs)\n",
    "    reg_avg[dt] = pd.concat([dfs[0][['smiles', 'y']], mean_values], axis=1).reset_index(drop=True)\n",
    "\n",
    "reg_avg['esol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53c9a50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for dt in ['esol', 'freesolv', 'lipophilicity']:\n",
    "    out = Path(f'Venn/regression')\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    df = reg_avg[dt][['y', 'MACCS', 'Morgan', '1D-CNN', 'ChemBERTa', '2D-GNN', '3D-GNN']]\n",
    "    corr_df = df[df.columns].corr()\n",
    "    \n",
    "    if dt == 'freesolv':\n",
    "        vmin, vmax = 0, 1\n",
    "    else:\n",
    "        # vmin, vmax = 0.5, 1\n",
    "        vmin, vmax = 0, 1\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr_df, annot=True, cmap='coolwarm', vmin=vmin, vmax=vmax)\n",
    "    plt.title(dt.upper())\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(out / f'{dt.upper()}.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f878f55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
