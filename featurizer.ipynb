{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\PARK\\anaconda3\\envs\\geometric\\Lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "2024.03.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rdkit\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem\n",
    "from deepchem.feat.smiles_tokenizer import BasicSmilesTokenizer\n",
    "from rdkit.Chem import Draw, AllChem, Descriptors, rdDepictor, rdDistGeom, MACCSkeys, rdMolDescriptors\n",
    "from rdkit.Chem import rdDepictor\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric import utils as pyg_utils\n",
    "from torch_geometric.data import InMemoryDataset, download_url, extract_gz, Data, DataLoader, Batch\n",
    "\n",
    "# # 작업을 위한 별도의 함수 불러오기\n",
    "# from utils.download_preprocess import CustomMoleculeNet, atom_features, EDGE_FEATURES\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(rdkit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARSMISET = {\"(\": 1, \".\": 2, \"0\": 3, \"2\": 4, \"4\": 5, \"6\": 6, \"8\": 7, \"@\": 8,\n",
    "                \"B\": 9, \"D\": 10, \"F\": 11, \"H\": 12, \"L\": 13, \"N\": 14, \"P\": 15, \"R\": 16,\n",
    "                \"T\": 17, \"V\": 18, \"Z\": 19, \"\\\\\": 20, \"b\": 21, \"d\": 22, \"f\": 23, \"h\": 24,\n",
    "                \"l\": 25, \"n\": 26, \"r\": 27, \"t\": 28, \"#\": 29, \"%\": 30, \")\": 31, \"+\": 32,\n",
    "                \"-\": 33, \"/\": 34, \"1\": 35, \"3\": 36, \"5\": 37, \"7\": 38, \"9\": 39, \"=\": 40,\n",
    "                \"A\": 41, \"C\": 42, \"E\": 43, \"G\": 44, \"I\": 45, \"K\": 46, \"M\": 47, \"O\": 48,\n",
    "                \"S\": 49, \"U\": 50, \"W\": 51, \"Y\": 52, \"[\": 53, \"]\": 54, \"a\": 55, \"c\": 56,\n",
    "                \"e\": 57, \"g\": 58, \"i\": 59, \"m\": 60, \"o\": 61, \"s\": 62, \"u\": 63, \"y\": 64, '~': 65} # add ~: 65 \n",
    "\n",
    "CHARISOSMILEN = 65\n",
    "\n",
    "CHARPROTSET = {\"A\": 1, \"C\": 2, \"B\": 3, \"E\": 4, \"D\": 5, \"G\": 6,\n",
    "               \"F\": 7, \"I\": 8, \"H\": 9, \"K\": 10, \"M\": 11, \"L\": 12,\n",
    "               \"O\": 13, \"N\": 14, \"Q\": 15, \"P\": 16, \"S\": 17, \"R\": 18,\n",
    "               \"U\": 19, \"T\": 20, \"W\": 21, \"V\": 22, \"Y\": 23, \"X\": 24, \"Z\": 25}\n",
    "\n",
    "CHARPROTLEN = 25\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "########## Function\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "def integer_label_encoding(sequence, tp, max_length=100):\n",
    "    \"\"\"\n",
    "    Integer encoding for string sequence.\n",
    "    Args:\n",
    "        sequence (str): Drug or Protein string sequence.\n",
    "        max_length: Maximum encoding length of input string.\n",
    "    \"\"\"\n",
    "    if tp == 'drug':\n",
    "        charset = CHARSMISET\n",
    "    elif tp == 'protein':\n",
    "        charset = CHARPROTSET\n",
    "\n",
    "    encoding = np.zeros(max_length)\n",
    "    for idx, letter in enumerate(sequence[:max_length]):\n",
    "        try:\n",
    "            if tp == 'protein':\n",
    "                letter = letter.upper()\n",
    "            letter = str(letter)\n",
    "            encoding[idx] = charset[letter]\n",
    "        except KeyError:\n",
    "            print(\n",
    "                f\"character {letter} does not exists in sequence category encoding, skip and treat as padding.\"\n",
    "            )\n",
    "    return Data(x=torch.from_numpy(encoding).to(torch.long).unsqueeze(dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_coord(smiles):\n",
    "    try:\n",
    "        # SMILES → Mol\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            print(f\"[Warning] MolFromSmiles failed for: {smiles}\")\n",
    "            return None\n",
    "        \n",
    "        mol = Chem.AddHs(mol)\n",
    "\n",
    "        # 3D 좌표 생성\n",
    "        status = AllChem.EmbedMolecule(mol, randomSeed=42)\n",
    "        if status != 0:\n",
    "            print(f\"[Warning] EmbedMolecule failed for: {smiles}\")\n",
    "            return None\n",
    "        \n",
    "        # 에너지 최소화\n",
    "        AllChem.UFFOptimizeMolecule(mol)\n",
    "\n",
    "        # conformer 가져오기\n",
    "        if mol.GetNumConformers() == 0:\n",
    "            print(f\"[Warning] No conformer generated for: {smiles}\")\n",
    "            return None\n",
    "        conf = mol.GetConformer()\n",
    "\n",
    "        # 원자 번호와 좌표 추출\n",
    "        z = []\n",
    "        pos = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            z.append(atom.GetAtomicNum())\n",
    "            p = conf.GetAtomPosition(atom.GetIdx())\n",
    "            pos.append([p.x, p.y, p.z])\n",
    "        \n",
    "        z = torch.tensor(z, dtype=torch.long)\n",
    "        pos = torch.tensor(pos, dtype=torch.float)\n",
    "        return Data(z=z, pos=pos)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Exception] Failed for {smiles}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "def smiles_to_chemberta_data(smiles, tokenizer, model):\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "from pathlib import Path\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "RDLogger.DisableLog('rdApp.*')  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (826572973.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[23], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    global\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "# Updated transform_mol function with progress logging\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "from utils.molecule_feature import *\n",
    "\n",
    "def transform_mol(molecule_smiles, labels, choice):\n",
    "    global \n",
    "    mols = [Chem.MolFromSmiles(mol) for mol in molecule_smiles if mol]\n",
    "    print(f\"Processing {len(molecule_smiles)} molecules with {choice} transformation...\")\n",
    "    \n",
    "    # string tokenization\n",
    "    if choice == 'string_tokenization': # vocab dictionary, encoded smiles를 출력\n",
    "        print(\"Building vocabulary from SMILES tokens...\")\n",
    "        vocab = []\n",
    "        max_len = 0\n",
    "        tokenizer = BasicSmilesTokenizer()\n",
    "        for smi in tqdm(molecule_smiles, desc=\"Tokenizing SMILES\"):\n",
    "            tokens = tokenizer.tokenize(smi)\n",
    "            max_len = max(max_len, len(tokens))\n",
    "            vocab += tokens\n",
    "            \n",
    "        uniq_vocab = sorted(set(vocab))\n",
    "        smiles_vocab = {v: i for i, v in enumerate(uniq_vocab)}\n",
    "        smiles_vocab['Unk'] = len(smiles_vocab)\n",
    "        print(f\"Vocabulary size: {len(smiles_vocab)}\")\n",
    "        \n",
    "        print(\"Encoding SMILES sequences...\")\n",
    "        encoded_smiles = [[smiles_vocab.get(token, smiles_vocab['Unk']) for token in tokenizer.tokenize(smi)] for smi in tqdm(molecule_smiles, desc=\"Encoding SMILES\")]\n",
    "        smiles_vec = []\n",
    "        for vec, l, smi in tqdm(zip(encoded_smiles, labels, molecule_smiles), desc=\"Creating Data objects\", total=len(molecule_smiles)):\n",
    "            pad_len = max_len - len(vec)\n",
    "            vec = vec + ([0] * pad_len)\n",
    "            smiles_vec.append(Data(x=torch.tensor(vec).view(1, -1), y=torch.tensor([l], dtype=torch.float).view(1, -1), smiles=smi))\n",
    "        print(f\"Completed string tokenization for {len(smiles_vec)} molecules\")\n",
    "        return smiles_vocab, smiles_vec\n",
    "\n",
    "    # integer encoding (CNN)\n",
    "    elif choice == 'integer_encoding':\n",
    "        print(\"Converting SMILES to integer encoding...\")\n",
    "        integer_encoding_data = []\n",
    "        for smi, l in tqdm(zip(molecule_smiles, labels), desc=\"Integer encoding\", total=len(molecule_smiles)):\n",
    "             drug = integer_label_encoding(smi, 'drug')\n",
    "             drug.y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "             integer_encoding_data.append(drug)\n",
    "        print(f\"Completed integer encoding for {len(integer_encoding_data)} molecules\")\n",
    "        return integer_encoding_data\n",
    "\n",
    "    # 2D Graph\n",
    "    elif choice == '2D_graph':\n",
    "        print(\"Converting SMILES to 2D molecular graphs...\")\n",
    "        graph_data = [smiles_to_feature(smi) for smi in tqdm(molecule_smiles, desc=\"Creating 2D graphs\")]\n",
    "\n",
    "        graph_2d = []\n",
    "        for g, l, smi in tqdm(zip(graph_data, labels, molecule_smiles), desc=\"Adding labels to graphs\", total=len(molecule_smiles)):\n",
    "            g.y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "            g.smiles = smi\n",
    "            graph_2d.append(g)\n",
    "        print(f\"Completed 2D graph conversion for {len(graph_2d)} molecules\")\n",
    "        return graph_2d\n",
    "\n",
    "    # 3D Graph\n",
    "    elif choice == '3D_graph':\n",
    "        print(\"Converting SMILES to 3D molecular graphs...\")\n",
    "        graph_3d = []\n",
    "        for smi, l in tqdm(zip(molecule_smiles, labels), desc=\"Creating 3D graphs\", total=len(molecule_smiles)):\n",
    "            graph_data = smiles_to_coord(smi)\n",
    "            if graph_data is None:\n",
    "                print(f\"Failed to create 3D graph for {smi}\")\n",
    "                continue\n",
    "            graph_data.y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "            graph_3d.append(graph_data)\n",
    "        print(f\"Completed 3D graph conversion for {len(graph_3d)} molecules\")\n",
    "        return graph_3d\n",
    "\n",
    "    # ChemBERTa\n",
    "    elif choice == 'chemberta':\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"DeepChem/ChemBERTa-77M-MLM\")\n",
    "        model = AutoModel.from_pretrained(\"DeepChem/ChemBERTa-77M-MLM\")\n",
    "        print(\"Converting SMILES to ChemBERTa embeddings...\")\n",
    "        chemberta_data = []\n",
    "        for smi, l in tqdm(zip(molecule_smiles, labels), desc=\"Creating ChemBERTa embeddings\", total=len(molecule_smiles)):\n",
    "            with torch.no_grad():\n",
    "                inputs = tokenizer(smi, return_tensors='pt', padding=True, truncation=True)\n",
    "                outputs = model(**inputs)\n",
    "                embedding = outputs.last_hidden_state[:, 0, :].squeeze(0)  # (hidden_size,)\n",
    "            data = Data(x=embedding, smiles=smi)\n",
    "            data.y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "            chemberta_data.append(data)\n",
    "        print(f\"Completed ChemBERTa embedding conversion for {len(chemberta_data)} molecules\")\n",
    "        return chemberta_data\n",
    "    \n",
    "    # Fingerprint\n",
    "    elif 'fingerprint' in choice:\n",
    "        print(f\"Generating {choice} fingerprints...\")\n",
    "        if choice == 'rdkit_fingerprint':\n",
    "            fp = [Chem.RDKFingerprint(mol) for mol in tqdm(mols, desc=\"RDKit fingerprints\")]\n",
    "        \n",
    "        elif choice == 'maccs_fingerprint':\n",
    "            fp = [MACCSkeys.GenMACCSKeys(mol) for mol in tqdm(mols, desc=\"MACCS fingerprints\")]\n",
    "        \n",
    "        elif choice == 'morgan_fingerprint':\n",
    "            fp = [AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024) for mol in tqdm(mols, desc=\"Morgan fingerprints\")]\n",
    "\n",
    "        print(\"Converting fingerprints to Data objects...\")\n",
    "        fps = [Data(x=torch.tensor(f).view(1, -1), y=torch.tensor([l], dtype=torch.float).view(1, -1), smiles=smi) for f, l, smi in tqdm(zip(fp, labels, molecule_smiles), desc=\"Creating fingerprint Data objects\", total=len(molecule_smiles))]\n",
    "        print(f\"Completed {choice} generation for {len(fps)} molecules\")\n",
    "        return fps\n",
    "\n",
    "    # Descriptors\n",
    "    elif choice == 'descriptors':\n",
    "        print(\"Calculating molecular descriptors...\")\n",
    "        # 모델 학습을 위해서는 스케일링 작업이 별도로 필요하다는 것을 기억하자!\n",
    "        desc = []\n",
    "        for mol, l, smi in tqdm(zip(mols, labels, molecule_smiles), desc=\"Calculating descriptors\", total=len(molecule_smiles)):\n",
    "            x = torch.tensor(list(Descriptors.CalcMolDescriptors(mol).values()), dtype=torch.float).view(1, -1)\n",
    "            y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "            desc.append(Data(x=x, y=y, smiles=smi))\n",
    "        print(f\"Completed descriptor calculation for {len(desc)} molecules\")\n",
    "        return desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dta_trn = pd.read_csv('dta_dataset/davis/train.csv')\n",
    "dta_val = pd.read_csv('dta_dataset/davis/valid.csv')\n",
    "dta_tst = pd.read_csv('dta_dataset/davis/test.csv')\n",
    "\n",
    "dta_trn['Set'] = 'TRN'\n",
    "dta_val['Set'] = 'VAL'\n",
    "dta_tst['Set'] = 'TST'\n",
    "\n",
    "dta = pd.concat([dta_trn, dta_val, dta_tst]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 25772 molecules with integer_encoding transformation...\n",
      "Converting SMILES to integer encoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Integer encoding: 100%|██████████| 25772/25772 [00:00<00:00, 29204.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed integer encoding for 25772 molecules\n",
      "Processing 25772 molecules with 2D_graph transformation...\n",
      "Converting SMILES to 2D molecular graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 2D graphs: 100%|██████████| 25772/25772 [00:21<00:00, 1198.49it/s]\n",
      "Adding labels to graphs: 100%|██████████| 25772/25772 [00:00<00:00, 146108.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2D graph conversion for 25772 molecules\n",
      "Processing 25772 molecules with morgan_fingerprint transformation...\n",
      "Generating morgan_fingerprint fingerprints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan fingerprints: 100%|██████████| 25772/25772 [00:01<00:00, 21031.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting fingerprints to Data objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating fingerprint Data objects: 100%|██████████| 25772/25772 [00:11<00:00, 2163.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed morgan_fingerprint generation for 25772 molecules\n",
      "Processing 25772 molecules with maccs_fingerprint transformation...\n",
      "Generating maccs_fingerprint fingerprints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MACCS fingerprints: 100%|██████████| 25772/25772 [00:30<00:00, 838.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting fingerprints to Data objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating fingerprint Data objects: 100%|██████████| 25772/25772 [00:02<00:00, 8679.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed maccs_fingerprint generation for 25772 molecules\n"
     ]
    }
   ],
   "source": [
    "dta['CNN'] = transform_mol(dta['Drug'], dta['Y'], 'integer_encoding')\n",
    "dta['2D-GNN'] = transform_mol(dta['Drug'], dta['Y'], '2D_graph')\n",
    "dta['FP-Morgan'] = transform_mol(dta['Drug'], dta['Y'], 'morgan_fingerprint') # 1024\n",
    "dta['FP-MACCS'] = transform_mol(dta['Drug'], dta['Y'], 'maccs_fingerprint') # 167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 25772 molecules with 3D_graph transformation...\n",
      "Converting SMILES to 3D molecular graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 3D graphs: 100%|██████████| 25772/25772 [23:27<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3D graph conversion for 25772 molecules\n"
     ]
    }
   ],
   "source": [
    "dta['3D-GNN'] = transform_mol(dta['Drug'], dta['Y'], '3D_graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 25772 molecules with chemberta transformation...\n",
      "Converting SMILES to ChemBERTa embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating ChemBERTa embeddings:   0%|          | 0/25772 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'tokenizer' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChemBERTa\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_mol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDrug\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchemberta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 78\u001b[0m, in \u001b[0;36mtransform_mol\u001b[1;34m(molecule_smiles, labels, choice)\u001b[0m\n\u001b[0;32m     76\u001b[0m chemberta_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m smi, l \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mzip\u001b[39m(molecule_smiles, labels), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating ChemBERTa embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(molecule_smiles)):\n\u001b[1;32m---> 78\u001b[0m     data \u001b[38;5;241m=\u001b[39m smiles_to_chemberta_data(smi, \u001b[43mtokenizer\u001b[49m, chemberta_model)\n\u001b[0;32m     79\u001b[0m     data\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([l], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     80\u001b[0m     chemberta_data\u001b[38;5;241m.\u001b[39mappend(data)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'tokenizer' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "dta['ChemBERTa'] = transform_mol(dta['Drug'], dta['Y'], 'chemberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta['Target_Rep'] = dta['Target'].apply(lambda x: integer_label_encoding(x, 'protein', 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dta_dataset\\davis\\feature\\3D-GNN\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "fd = Path('dta_dataset/davis/feature/')\n",
    "fd.mkdir(parents=True, exist_ok=True)\n",
    "# for ft in ['CNN', '2D-GNN', 'FP-Morgan', 'FP-MACCS']:\n",
    "# for ft in ['3D-GNN', 'ChemBERTa']:\n",
    "for ft in ['ChemBERTa']:\n",
    "    nfd = fd / ft\n",
    "    nfd.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    trn_sub = dta[dta['Set'] == 'TRN'][[ft, 'Target_Rep']].reset_index(drop=True).rename(columns={ft: 'Drug_Rep'}).to_dict('records')\n",
    "    val_sub = dta[dta['Set'] == 'VAL'][[ft, 'Target_Rep']].reset_index(drop=True).rename(columns={ft: 'Drug_Rep'}).to_dict('records')\n",
    "    tst_sub = dta[dta['Set'] == 'TST'][[ft, 'Target_Rep']].reset_index(drop=True).rename(columns={ft: 'Drug_Rep'}).to_dict('records')\n",
    "    # print(f'{ft} feature_dim', dta[ft].values[0].x.shape)\n",
    "    \n",
    "    with open(nfd / 'trn.pkl', 'wb') as f:\n",
    "        pickle.dump(trn_sub, f)\n",
    "    with open(nfd / 'val.pkl', 'wb') as f:\n",
    "        pickle.dump(val_sub, f)\n",
    "    with open(nfd / 'tst.pkl', 'wb') as f:\n",
    "        pickle.dump(tst_sub, f)\n",
    "    \n",
    "    print('Saved', nfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(pos=[49, 3], z=[49], y=[1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta[ft].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(dta['3D-GNN'].values[0].pos).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc = pd.read_csv('data/zinc/zinc15_250K.csv')\n",
    "zinc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_mol_nolabel(molecule_smiles, choice):\n",
    "    mols = [Chem.MolFromSmiles(mol) for mol in molecule_smiles if mol]\n",
    "    print(f\"Processing {len(molecule_smiles)} molecules with {choice} transformation...\")\n",
    "    \n",
    "     # integer encoding (CNN)\n",
    "    if choice == 'integer_encoding':\n",
    "        print(\"Converting SMILES to integer encoding...\")\n",
    "        integer_encoding_data = {}\n",
    "        for smi in tqdm(molecule_smiles):\n",
    "             drug = integer_label_encoding(smi, 'drug')\n",
    "             integer_encoding_data[smi] = drug\n",
    "        print(f\"Completed integer encoding for {len(integer_encoding_data)} molecules\")\n",
    "        return integer_encoding_data\n",
    "\n",
    "    # 2D Graph\n",
    "    elif choice == '2D_graph':\n",
    "        print(\"Converting SMILES to 2D molecular graphs...\")\n",
    "        graph_data = {smi: drug_to_graph(smi) for smi in tqdm(molecule_smiles, desc=\"Creating 2D graphs\")}\n",
    "        print(f\"Completed 2D graph conversion for {len(graph_data)} molecules\")\n",
    "        return graph_data\n",
    "\n",
    "    # 3D Graph\n",
    "    elif choice == '3D_graph':\n",
    "        print(\"Converting SMILES to 3D molecular graphs...\")\n",
    "        graph_3d = {}\n",
    "        for smi in tqdm(molecule_smiles):\n",
    "            graph_data = drug_to_graph(smi)\n",
    "            \n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            atom_info = [(atom.GetIdx(), atom.GetSymbol()) for atom in mol.GetAtoms()]\n",
    "                     \n",
    "            mol = AllChem.AddHs(mol, addCoords=True)\n",
    "            emb_mol = rdDistGeom.EmbedMolecule(mol)\n",
    "            if emb_mol == -1:\n",
    "                rdDepictor.Compute2DCoords(mol)\n",
    "\n",
    "            conf = mol.GetConformer()\n",
    "            pos = np.array([conf.GetAtomPosition(idx) for idx, symbol in atom_info])\n",
    "            graph_data.pos = pos\n",
    "            graph_3d[smi] = graph_data\n",
    "        print(f\"Completed 3D graph conversion for {len(graph_3d)} molecules\")\n",
    "        return graph_3d\n",
    "    \n",
    "    # Fingerprint\n",
    "    elif 'fingerprint' in choice:\n",
    "        print(f\"Generating {choice} fingerprints...\")\n",
    "        if choice == 'rdkit_fingerprint':\n",
    "            fp = [Chem.RDKFingerprint(mol) for mol in tqdm(mols, desc=\"RDKit fingerprints\")]\n",
    "        \n",
    "        elif choice == 'maccs_fingerprint':\n",
    "            fp = [MACCSkeys.GenMACCSKeys(mol) for mol in tqdm(mols, desc=\"MACCS fingerprints\")]\n",
    "        \n",
    "        elif choice == 'morgan_fingerprint':\n",
    "            fp = [AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024) for mol in tqdm(mols, desc=\"Morgan fingerprints\")]\n",
    "\n",
    "        print(\"Converting fingerprints to Data objects...\")\n",
    "        fps = {smi: Data(x=torch.tensor(f).view(1, -1)) for f, smi in tqdm(zip(fp, molecule_smiles), desc=\"Creating fingerprint Data objects\")}\n",
    "        print(f\"Completed {choice} generation for {len(fps)} molecules\")\n",
    "        return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc_cnn = transform_mol_nolabel(zinc['smiles'], 'integer_encoding')\n",
    "with open('data/zinc/feature/zinc_cnn.pkl', 'wb') as f:\n",
    "    pickle.dump(zinc_cnn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc_2d_gnn = transform_mol_nolabel(zinc['smiles'], '2D_graph')\n",
    "with open('data/zinc/feature/zinc_2d_gnn.pkl', 'wb') as f:\n",
    "    pickle.dump(zinc_2d_gnn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc_fp_morgan = transform_mol_nolabel(zinc['smiles'], 'morgan_fingerprint')\n",
    "with open('data/zinc/feature/zinc_fp_morgan.pkl', 'wb') as f:\n",
    "    pickle.dump(zinc_fp_morgan, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc_fp_maccs = transform_mol_nolabel(zinc['smiles'], 'maccs_fingerprint')\n",
    "with open('data/zinc/feature/zinc_fp_maccs.pkl', 'wb') as f:\n",
    "    pickle.dump(zinc_fp_maccs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc_3d_gnn = transform_mol_nolabel(zinc['smiles'], '3D_graph')\n",
    "with open('data/zinc/feature/zinc_3d_gnn.pkl', 'wb') as f:\n",
    "    pickle.dump(zinc_3d_gnn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/zinc/feature/zinc_3d_gnn.pkl', 'wb') as f:\n",
    "    pickle.dump(zinc_3d_gnn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '20250628'\n",
    "for dt in ['bace', 'bbbp', 'tox21', 'toxcast', 'sider', 'clintox', 'hiv']:\n",
    "    for ft in ['3D-GNN']:\n",
    "        cmd = f\"python Train_Property.py --dataset {dt} --feature {ft} --filename {name} --project {dt.upper()}_{ft}_{name}  > ./logs/new/{dt}_{ft}.txt\"\n",
    "        print(cmd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '20250627'\n",
    "for dt in ['bace', 'bbbp', 'tox21', 'toxcast', 'sider', 'clintox', 'hiv']:\n",
    "    for ft in ['FP-Morgan', 'FP-MACCS', 'CNN']:\n",
    "        cmd = f\"python Train_Property.py --dataset {dt} --feature {ft} --filename {name} --project {dt.upper()}_{ft}_{name}  > ./logs/new/{dt}_{ft}.txt\"\n",
    "        print(cmd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "embeddings = outputs.last_hidden_state[:,0,:]  # (batch_size, hidden_size)\n",
    "\n",
    "print(embeddings.shape)  # 예: torch.Size([3, 384])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = smiles_to_coord('CCO')\n",
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
