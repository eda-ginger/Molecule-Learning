{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\PARK\\anaconda3\\envs\\grapose\\Lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "2025.03.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rdkit\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem\n",
    "from deepchem.feat.smiles_tokenizer import BasicSmilesTokenizer\n",
    "from rdkit.Chem import Draw, AllChem, Descriptors, rdDepictor, rdDistGeom, MACCSkeys, rdMolDescriptors\n",
    "from rdkit.Chem import rdDepictor\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric import utils as pyg_utils\n",
    "from torch_geometric.data import InMemoryDataset, download_url, extract_gz, Data, DataLoader, Batch\n",
    "\n",
    "# # 작업을 위한 별도의 함수 불러오기\n",
    "# from utils.download_preprocess import CustomMoleculeNet, atom_features, EDGE_FEATURES\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(rdkit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARSMISET = {\"(\": 1, \".\": 2, \"0\": 3, \"2\": 4, \"4\": 5, \"6\": 6, \"8\": 7, \"@\": 8,\n",
    "                \"B\": 9, \"D\": 10, \"F\": 11, \"H\": 12, \"L\": 13, \"N\": 14, \"P\": 15, \"R\": 16,\n",
    "                \"T\": 17, \"V\": 18, \"Z\": 19, \"\\\\\": 20, \"b\": 21, \"d\": 22, \"f\": 23, \"h\": 24,\n",
    "                \"l\": 25, \"n\": 26, \"r\": 27, \"t\": 28, \"#\": 29, \"%\": 30, \")\": 31, \"+\": 32,\n",
    "                \"-\": 33, \"/\": 34, \"1\": 35, \"3\": 36, \"5\": 37, \"7\": 38, \"9\": 39, \"=\": 40,\n",
    "                \"A\": 41, \"C\": 42, \"E\": 43, \"G\": 44, \"I\": 45, \"K\": 46, \"M\": 47, \"O\": 48,\n",
    "                \"S\": 49, \"U\": 50, \"W\": 51, \"Y\": 52, \"[\": 53, \"]\": 54, \"a\": 55, \"c\": 56,\n",
    "                \"e\": 57, \"g\": 58, \"i\": 59, \"m\": 60, \"o\": 61, \"s\": 62, \"u\": 63, \"y\": 64, '~': 65} # add ~: 65 \n",
    "\n",
    "CHARISOSMILEN = 65\n",
    "\n",
    "CHARPROTSET = {\"A\": 1, \"C\": 2, \"B\": 3, \"E\": 4, \"D\": 5, \"G\": 6,\n",
    "               \"F\": 7, \"I\": 8, \"H\": 9, \"K\": 10, \"M\": 11, \"L\": 12,\n",
    "               \"O\": 13, \"N\": 14, \"Q\": 15, \"P\": 16, \"S\": 17, \"R\": 18,\n",
    "               \"U\": 19, \"T\": 20, \"W\": 21, \"V\": 22, \"Y\": 23, \"X\": 24, \"Z\": 25}\n",
    "\n",
    "CHARPROTLEN = 25\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "########## Function\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "def integer_label_encoding(sequence, tp, max_length=100):\n",
    "    \"\"\"\n",
    "    Integer encoding for string sequence.\n",
    "    Args:\n",
    "        sequence (str): Drug or Protein string sequence.\n",
    "        max_length: Maximum encoding length of input string.\n",
    "    \"\"\"\n",
    "    if tp == 'drug':\n",
    "        charset = CHARSMISET\n",
    "    elif tp == 'protein':\n",
    "        charset = CHARPROTSET\n",
    "\n",
    "    encoding = np.zeros(max_length)\n",
    "    for idx, letter in enumerate(sequence[:max_length]):\n",
    "        try:\n",
    "            if tp == 'protein':\n",
    "                letter = letter.upper()\n",
    "            letter = str(letter)\n",
    "            encoding[idx] = charset[letter]\n",
    "        except KeyError:\n",
    "            print(\n",
    "                f\"character {letter} does not exists in sequence category encoding, skip and treat as padding.\"\n",
    "            )\n",
    "    return Data(x=torch.from_numpy(encoding).to(torch.long).unsqueeze(dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "from pathlib import Path\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "RDLogger.DisableLog('rdApp.*')  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "# Updated transform_mol function with progress logging\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "from utils.molecule_feature import *\n",
    "\n",
    "def transform_mol(molecule_smiles, labels, choice):\n",
    "    mols = [Chem.MolFromSmiles(mol) for mol in molecule_smiles if mol]\n",
    "    print(f\"Processing {len(molecule_smiles)} molecules with {choice} transformation...\")\n",
    "    \n",
    "    # string tokenization\n",
    "    if choice == 'string_tokenization': # vocab dictionary, encoded smiles를 출력\n",
    "        print(\"Building vocabulary from SMILES tokens...\")\n",
    "        vocab = []\n",
    "        max_len = 0\n",
    "        tokenizer = BasicSmilesTokenizer()\n",
    "        for smi in tqdm(molecule_smiles, desc=\"Tokenizing SMILES\"):\n",
    "            tokens = tokenizer.tokenize(smi)\n",
    "            max_len = max(max_len, len(tokens))\n",
    "            vocab += tokens\n",
    "            \n",
    "        uniq_vocab = sorted(set(vocab))\n",
    "        smiles_vocab = {v: i for i, v in enumerate(uniq_vocab)}\n",
    "        smiles_vocab['Unk'] = len(smiles_vocab)\n",
    "        print(f\"Vocabulary size: {len(smiles_vocab)}\")\n",
    "        \n",
    "        print(\"Encoding SMILES sequences...\")\n",
    "        encoded_smiles = [[smiles_vocab.get(token, smiles_vocab['Unk']) for token in tokenizer.tokenize(smi)] for smi in tqdm(molecule_smiles, desc=\"Encoding SMILES\")]\n",
    "        smiles_vec = []\n",
    "        for vec, l, smi in tqdm(zip(encoded_smiles, labels, molecule_smiles), desc=\"Creating Data objects\", total=len(molecule_smiles)):\n",
    "            pad_len = max_len - len(vec)\n",
    "            vec = vec + ([0] * pad_len)\n",
    "            smiles_vec.append(Data(x=torch.tensor(vec).view(1, -1), y=torch.tensor([l], dtype=torch.float).view(1, -1), smiles=smi))\n",
    "        print(f\"Completed string tokenization for {len(smiles_vec)} molecules\")\n",
    "        return smiles_vocab, smiles_vec\n",
    "\n",
    "    # integer encoding (CNN)\n",
    "    elif choice == 'integer_encoding':\n",
    "        print(\"Converting SMILES to integer encoding...\")\n",
    "        integer_encoding_data = []\n",
    "        for smi, l in tqdm(zip(molecule_smiles, labels), desc=\"Integer encoding\", total=len(molecule_smiles)):\n",
    "             drug = integer_label_encoding(smi, 'drug')\n",
    "             drug.y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "             integer_encoding_data.append(drug)\n",
    "        print(f\"Completed integer encoding for {len(integer_encoding_data)} molecules\")\n",
    "        return integer_encoding_data\n",
    "\n",
    "    # 2D Graph\n",
    "    elif choice == '2D_graph':\n",
    "        print(\"Converting SMILES to 2D molecular graphs...\")\n",
    "        graph_data = [smiles_to_feature(smi) for smi in tqdm(molecule_smiles, desc=\"Creating 2D graphs\")]\n",
    "\n",
    "        graph_2d = []\n",
    "        for g, l, smi in tqdm(zip(graph_data, labels, molecule_smiles), desc=\"Adding labels to graphs\", total=len(molecule_smiles)):\n",
    "            g.y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "            g.smiles = smi\n",
    "            graph_2d.append(g)\n",
    "        print(f\"Completed 2D graph conversion for {len(graph_2d)} molecules\")\n",
    "        return graph_2d\n",
    "\n",
    "    # 3D Graph\n",
    "    elif choice == '3D_graph':\n",
    "        print(\"Converting SMILES to 3D molecular graphs...\")\n",
    "        graph_3d = []\n",
    "        for smi, l in tqdm(zip(molecule_smiles, labels), desc=\"Creating 3D graphs\", total=len(molecule_smiles)):\n",
    "            graph_data = smiles_to_feature(smi)\n",
    "            \n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            atom_info = [(atom.GetIdx(), atom.GetSymbol()) for atom in mol.GetAtoms()]\n",
    "                     \n",
    "            mol = AllChem.AddHs(mol, addCoords=True)\n",
    "            rdDistGeom.EmbedMolecule(mol)\n",
    "    \n",
    "            conf = mol.GetConformer()\n",
    "            pos = np.array([conf.GetAtomPosition(idx) for idx, symbol in atom_info])\n",
    "            graph_data.pos = pos\n",
    "            graph_data.y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "            graph_data.smiles = smi\n",
    "            graph_3d.append(graph_data)\n",
    "        print(f\"Completed 3D graph conversion for {len(graph_3d)} molecules\")\n",
    "        return graph_3d\n",
    "    \n",
    "    # Fingerprint\n",
    "    elif 'fingerprint' in choice:\n",
    "        print(f\"Generating {choice} fingerprints...\")\n",
    "        if choice == 'rdkit_fingerprint':\n",
    "            fp = [Chem.RDKFingerprint(mol) for mol in tqdm(mols, desc=\"RDKit fingerprints\")]\n",
    "        \n",
    "        elif choice == 'maccs_fingerprint':\n",
    "            fp = [MACCSkeys.GenMACCSKeys(mol) for mol in tqdm(mols, desc=\"MACCS fingerprints\")]\n",
    "        \n",
    "        elif choice == 'morgan_fingerprint':\n",
    "            fp = [AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024) for mol in tqdm(mols, desc=\"Morgan fingerprints\")]\n",
    "\n",
    "        print(\"Converting fingerprints to Data objects...\")\n",
    "        fps = [Data(x=torch.tensor(f).view(1, -1), y=torch.tensor([l], dtype=torch.float).view(1, -1), smiles=smi) for f, l, smi in tqdm(zip(fp, labels, molecule_smiles), desc=\"Creating fingerprint Data objects\", total=len(molecule_smiles))]\n",
    "        print(f\"Completed {choice} generation for {len(fps)} molecules\")\n",
    "        return fps\n",
    "\n",
    "    # Descriptors\n",
    "    elif choice == 'descriptors':\n",
    "        print(\"Calculating molecular descriptors...\")\n",
    "        # 모델 학습을 위해서는 스케일링 작업이 별도로 필요하다는 것을 기억하자!\n",
    "        desc = []\n",
    "        for mol, l, smi in tqdm(zip(mols, labels, molecule_smiles), desc=\"Calculating descriptors\", total=len(molecule_smiles)):\n",
    "            x = torch.tensor(list(Descriptors.CalcMolDescriptors(mol).values()), dtype=torch.float).view(1, -1)\n",
    "            y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "            desc.append(Data(x=x, y=y, smiles=smi))\n",
    "        print(f\"Completed descriptor calculation for {len(desc)} molecules\")\n",
    "        return desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dta_trn = pd.read_csv('data/davis/train.csv')\n",
    "dta_val = pd.read_csv('data/davis/valid.csv')\n",
    "dta_tst = pd.read_csv('data/davis/test.csv')\n",
    "\n",
    "dta_trn['Set'] = 'TRN'\n",
    "dta_val['Set'] = 'VAL'\n",
    "dta_tst['Set'] = 'TST'\n",
    "\n",
    "dta = pd.concat([dta_trn, dta_val, dta_tst]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 25772 molecules with integer_encoding transformation...\n",
      "Converting SMILES to integer encoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Integer encoding: 100%|██████████| 25772/25772 [00:00<00:00, 30457.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed integer encoding for 25772 molecules\n",
      "Processing 25772 molecules with 2D_graph transformation...\n",
      "Converting SMILES to 2D molecular graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 2D graphs: 100%|██████████| 25772/25772 [00:20<00:00, 1258.35it/s]\n",
      "Adding labels to graphs: 100%|██████████| 25772/25772 [00:00<00:00, 148506.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2D graph conversion for 25772 molecules\n",
      "Processing 25772 molecules with morgan_fingerprint transformation...\n",
      "Generating morgan_fingerprint fingerprints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Morgan fingerprints: 100%|██████████| 25772/25772 [00:00<00:00, 29844.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting fingerprints to Data objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating fingerprint Data objects: 100%|██████████| 25772/25772 [00:11<00:00, 2226.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed morgan_fingerprint generation for 25772 molecules\n",
      "Processing 25772 molecules with maccs_fingerprint transformation...\n",
      "Generating maccs_fingerprint fingerprints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MACCS fingerprints: 100%|██████████| 25772/25772 [00:29<00:00, 885.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting fingerprints to Data objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating fingerprint Data objects: 100%|██████████| 25772/25772 [00:02<00:00, 9098.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed maccs_fingerprint generation for 25772 molecules\n"
     ]
    }
   ],
   "source": [
    "dta['CNN'] = transform_mol(dta['Drug'], dta['Y'], 'integer_encoding')\n",
    "dta['2D-GNN'] = transform_mol(dta['Drug'], dta['Y'], '2D_graph')\n",
    "dta['FP-Morgan'] = transform_mol(dta['Drug'], dta['Y'], 'morgan_fingerprint') # 1024\n",
    "dta['FP-MACCS'] = transform_mol(dta['Drug'], dta['Y'], 'maccs_fingerprint') # 167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[27, 133], edge_index=[2, 60], edge_attr=[60, 2], smiles='Cc1[nH]nc2ccc(-c3cncc(OCC(N)Cc4ccccc4)c3)cc12', y=[1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta['2D-GNN'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta['3D-GNN'] = transform_mol(dta['Drug'], dta['Y'], '3D_graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta['Target_Rep'] = dta['Target'].apply(lambda x: integer_label_encoding(x, 'protein', 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN feature_dim torch.Size([1, 100])\n",
      "Saved data\\davis\\feature\\CNN\n",
      "2D-GNN feature_dim torch.Size([27, 133])\n",
      "Saved data\\davis\\feature\\2D-GNN\n",
      "FP-Morgan feature_dim torch.Size([1, 1024])\n",
      "Saved data\\davis\\feature\\FP-Morgan\n",
      "FP-MACCS feature_dim torch.Size([1, 167])\n",
      "Saved data\\davis\\feature\\FP-MACCS\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "fd = Path('data/davis/feature/')\n",
    "fd.mkdir(parents=True, exist_ok=True)\n",
    "for ft in ['CNN', '2D-GNN', 'FP-Morgan', 'FP-MACCS']:\n",
    "    nfd = fd / ft\n",
    "    nfd.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    trn_sub = dta[dta['Set'] == 'TRN'][[ft, 'Target_Rep']].reset_index(drop=True).rename(columns={ft: 'Drug_Rep'}).to_dict('records')\n",
    "    val_sub = dta[dta['Set'] == 'VAL'][[ft, 'Target_Rep']].reset_index(drop=True).rename(columns={ft: 'Drug_Rep'}).to_dict('records')\n",
    "    tst_sub = dta[dta['Set'] == 'TST'][[ft, 'Target_Rep']].reset_index(drop=True).rename(columns={ft: 'Drug_Rep'}).to_dict('records')\n",
    "    print(f'{ft} feature_dim', dta[ft].values[0].x.shape)\n",
    "    \n",
    "    with open(nfd / 'trn.pkl', 'wb') as f:\n",
    "        pickle.dump(trn_sub, f)\n",
    "    with open(nfd / 'val.pkl', 'wb') as f:\n",
    "        pickle.dump(val_sub, f)\n",
    "    with open(nfd / 'tst.pkl', 'wb') as f:\n",
    "        pickle.dump(tst_sub, f)\n",
    "    \n",
    "    print('Saved', nfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(dta['3D-GNN'].values[0].pos).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc = pd.read_csv('data/zinc/zinc15_250K.csv')\n",
    "zinc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_mol_nolabel(molecule_smiles, choice):\n",
    "    mols = [Chem.MolFromSmiles(mol) for mol in molecule_smiles if mol]\n",
    "    print(f\"Processing {len(molecule_smiles)} molecules with {choice} transformation...\")\n",
    "    \n",
    "     # integer encoding (CNN)\n",
    "    if choice == 'integer_encoding':\n",
    "        print(\"Converting SMILES to integer encoding...\")\n",
    "        integer_encoding_data = {}\n",
    "        for smi in tqdm(molecule_smiles):\n",
    "             drug = integer_label_encoding(smi, 'drug')\n",
    "             integer_encoding_data[smi] = drug\n",
    "        print(f\"Completed integer encoding for {len(integer_encoding_data)} molecules\")\n",
    "        return integer_encoding_data\n",
    "\n",
    "    # 2D Graph\n",
    "    elif choice == '2D_graph':\n",
    "        print(\"Converting SMILES to 2D molecular graphs...\")\n",
    "        graph_data = {smi: drug_to_graph(smi) for smi in tqdm(molecule_smiles, desc=\"Creating 2D graphs\")}\n",
    "        print(f\"Completed 2D graph conversion for {len(graph_data)} molecules\")\n",
    "        return graph_data\n",
    "\n",
    "    # 3D Graph\n",
    "    elif choice == '3D_graph':\n",
    "        print(\"Converting SMILES to 3D molecular graphs...\")\n",
    "        graph_3d = {}\n",
    "        for smi in tqdm(molecule_smiles):\n",
    "            graph_data = drug_to_graph(smi)\n",
    "            \n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            atom_info = [(atom.GetIdx(), atom.GetSymbol()) for atom in mol.GetAtoms()]\n",
    "                     \n",
    "            mol = AllChem.AddHs(mol, addCoords=True)\n",
    "            emb_mol = rdDistGeom.EmbedMolecule(mol)\n",
    "            if emb_mol == -1:\n",
    "                rdDepictor.Compute2DCoords(mol)\n",
    "\n",
    "            conf = mol.GetConformer()\n",
    "            pos = np.array([conf.GetAtomPosition(idx) for idx, symbol in atom_info])\n",
    "            graph_data.pos = pos\n",
    "            graph_3d[smi] = graph_data\n",
    "        print(f\"Completed 3D graph conversion for {len(graph_3d)} molecules\")\n",
    "        return graph_3d\n",
    "    \n",
    "    # Fingerprint\n",
    "    elif 'fingerprint' in choice:\n",
    "        print(f\"Generating {choice} fingerprints...\")\n",
    "        if choice == 'rdkit_fingerprint':\n",
    "            fp = [Chem.RDKFingerprint(mol) for mol in tqdm(mols, desc=\"RDKit fingerprints\")]\n",
    "        \n",
    "        elif choice == 'maccs_fingerprint':\n",
    "            fp = [MACCSkeys.GenMACCSKeys(mol) for mol in tqdm(mols, desc=\"MACCS fingerprints\")]\n",
    "        \n",
    "        elif choice == 'morgan_fingerprint':\n",
    "            fp = [AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024) for mol in tqdm(mols, desc=\"Morgan fingerprints\")]\n",
    "\n",
    "        print(\"Converting fingerprints to Data objects...\")\n",
    "        fps = {smi: Data(x=torch.tensor(f).view(1, -1)) for f, smi in tqdm(zip(fp, molecule_smiles), desc=\"Creating fingerprint Data objects\")}\n",
    "        print(f\"Completed {choice} generation for {len(fps)} molecules\")\n",
    "        return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc_cnn = transform_mol_nolabel(zinc['smiles'], 'integer_encoding')\n",
    "with open('data/zinc/feature/zinc_cnn.pkl', 'wb') as f:\n",
    "    pickle.dump(zinc_cnn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc_2d_gnn = transform_mol_nolabel(zinc['smiles'], '2D_graph')\n",
    "with open('data/zinc/feature/zinc_2d_gnn.pkl', 'wb') as f:\n",
    "    pickle.dump(zinc_2d_gnn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc_fp_morgan = transform_mol_nolabel(zinc['smiles'], 'morgan_fingerprint')\n",
    "with open('data/zinc/feature/zinc_fp_morgan.pkl', 'wb') as f:\n",
    "    pickle.dump(zinc_fp_morgan, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc_fp_maccs = transform_mol_nolabel(zinc['smiles'], 'maccs_fingerprint')\n",
    "with open('data/zinc/feature/zinc_fp_maccs.pkl', 'wb') as f:\n",
    "    pickle.dump(zinc_fp_maccs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc_3d_gnn = transform_mol_nolabel(zinc['smiles'], '3D_graph')\n",
    "with open('data/zinc/feature/zinc_3d_gnn.pkl', 'wb') as f:\n",
    "    pickle.dump(zinc_3d_gnn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/zinc/feature/zinc_3d_gnn.pkl', 'wb') as f:\n",
    "    pickle.dump(zinc_3d_gnn, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepchem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "from rdkit import Chem, RDLogger\n",
    "\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "from deepchem.feat import MolGraphConvFeaturizer, CircularFingerprint, MACCSKeysFingerprint\n",
    "from deepchem.splits import RandomSplitter, ScaffoldSplitter\n",
    "\n",
    "# # splitter\n",
    "# random_splitter = RandomSplitter()\n",
    "# scaffold_splitter = ScaffoldSplitter()\n",
    "\n",
    "# # featurizer\n",
    "# maccs_featurizer = MACCSKeysFingerprint()\n",
    "# morgan_featurizer = CircularFingerprint(size=1024, radius=2)\n",
    "# graph_featurizer = MolGraphConvFeaturizer(use_edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.molnet import load_freesolv, load_bbbp, load_clintox, load_hiv, load_lipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bace \n",
    "d1 = dc.molnet.load_bace_classification(data_dir='./data/molnet/bace/', save_dir='./data/molnet/bace/FP-Morgan', featurizer=morgan_featurizer, splitter=scaffold_splitter)\n",
    "d2 = dc.molnet.load_bace_classification(data_dir='./data/molnet/bace/', save_dir='./data/molnet/bace/FP-MACCS', featurizer=maccs_featurizer, splitter=scaffold_splitter)\n",
    "d3 = dc.molnet.load_bace_classification(data_dir='./data/molnet/bace/', save_dir='./data/molnet/bace/2D-Graph', featurizer=graph_featurizer, splitter=scaffold_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbbp \n",
    "d1 = dc.molnet.load_bbbp(data_dir='./data/molnet/bbbp/', save_dir='./data/molnet/bbbp/FP-Morgan', featurizer=morgan_featurizer, splitter=scaffold_splitter)\n",
    "d2 = dc.molnet.load_bbbp(data_dir='./data/molnet/bbbp/', save_dir='./data/molnet/bbbp/FP-MACCS', featurizer=maccs_featurizer, splitter=scaffold_splitter)\n",
    "d3 = dc.molnet.load_bbbp(data_dir='./data/molnet/bbbp/', save_dir='./data/molnet/bbbp/2D-Graph', featurizer=graph_featurizer, splitter=scaffold_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freesolv\n",
    "d1 = dc.molnet.load_freesolv(data_dir='./data/molnet/freesolv/', save_dir='./data/molnet/freesolv/FP-Morgan', featurizer=morgan_featurizer, splitter=random_splitter)\n",
    "d2 = dc.molnet.load_freesolv(data_dir='./data/molnet/freesolv/', save_dir='./data/molnet/freesolv/FP-MACCS', featurizer=maccs_featurizer, splitter=random_splitter)\n",
    "d3 = dc.molnet.load_freesolv(data_dir='./data/molnet/freesolv/', save_dir='./data/molnet/freesolv/2D-Graph', featurizer=graph_featurizer, splitter=random_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esol\n",
    "d1 = dc.molnet.load_delaney(data_dir='./data/molnet/esol/', save_dir='./data/molnet/esol/FP-Morgan', featurizer=morgan_featurizer, splitter=random_splitter)\n",
    "d2 = dc.molnet.load_delaney(data_dir='./data/molnet/esol/', save_dir='./data/molnet/esol/FP-MACCS', featurizer=maccs_featurizer, splitter=random_splitter)\n",
    "d3 = dc.molnet.load_delaney(data_dir='./data/molnet/esol/', save_dir='./data/molnet/esol/2D-Graph', featurizer=graph_featurizer, splitter=random_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lipo\n",
    "d1 = dc.molnet.load_lipo(data_dir='./data/molnet/lipo/', save_dir='./data/molnet/lipo/FP-Morgan', featurizer=morgan_featurizer, splitter=random_splitter)\n",
    "d2 = dc.molnet.load_lipo(data_dir='./data/molnet/lipo/', save_dir='./data/molnet/lipo/FP-MACCS', featurizer=maccs_featurizer, splitter=random_splitter)\n",
    "d3 = dc.molnet.load_lipo(data_dir='./data/molnet/lipo/', save_dir='./data/molnet/lipo/2D-Graph', featurizer=graph_featurizer, splitter=random_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clintox\n",
    "d1 = dc.molnet.load_clintox(data_dir='./data/molnet/clintox/', save_dir='./data/molnet/clintox/FP-Morgan', featurizer=morgan_featurizer, splitter=random_splitter)\n",
    "d2 = dc.molnet.load_clintox(data_dir='./data/molnet/clintox/', save_dir='./data/molnet/clintox/FP-MACCS', featurizer=maccs_featurizer, splitter=random_splitter)\n",
    "d3 = dc.molnet.load_clintox(data_dir='./data/molnet/clintox/', save_dir='./data/molnet/clintox/2D-Graph', featurizer=graph_featurizer, splitter=random_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Train_Property.py --dataset bace --feature FP-Morgan --model_type scaffold --project BACE_FP-Morgan_scaffold > BACE_FP-Morgan_scaffold_.txt\n",
      "python Train_Property.py --dataset bace --feature FP-MACCS --model_type scaffold --project BACE_FP-MACCS_scaffold > BACE_FP-MACCS_scaffold_.txt\n",
      "python Train_Property.py --dataset bace --feature CNN --model_type scaffold --project BACE_CNN_scaffold > BACE_CNN_scaffold_.txt\n",
      "python Train_Property.py --dataset bbbp --feature FP-Morgan --model_type scaffold --project BBBP_FP-Morgan_scaffold > BBBP_FP-Morgan_scaffold_.txt\n",
      "python Train_Property.py --dataset bbbp --feature FP-MACCS --model_type scaffold --project BBBP_FP-MACCS_scaffold > BBBP_FP-MACCS_scaffold_.txt\n",
      "python Train_Property.py --dataset bbbp --feature CNN --model_type scaffold --project BBBP_CNN_scaffold > BBBP_CNN_scaffold_.txt\n",
      "python Train_Property.py --dataset tox21 --feature FP-Morgan --model_type scaffold --project TOX21_FP-Morgan_scaffold > TOX21_FP-Morgan_scaffold_.txt\n",
      "python Train_Property.py --dataset tox21 --feature FP-MACCS --model_type scaffold --project TOX21_FP-MACCS_scaffold > TOX21_FP-MACCS_scaffold_.txt\n",
      "python Train_Property.py --dataset tox21 --feature CNN --model_type scaffold --project TOX21_CNN_scaffold > TOX21_CNN_scaffold_.txt\n",
      "python Train_Property.py --dataset toxcast --feature FP-Morgan --model_type scaffold --project TOXCAST_FP-Morgan_scaffold > TOXCAST_FP-Morgan_scaffold_.txt\n",
      "python Train_Property.py --dataset toxcast --feature FP-MACCS --model_type scaffold --project TOXCAST_FP-MACCS_scaffold > TOXCAST_FP-MACCS_scaffold_.txt\n",
      "python Train_Property.py --dataset toxcast --feature CNN --model_type scaffold --project TOXCAST_CNN_scaffold > TOXCAST_CNN_scaffold_.txt\n",
      "python Train_Property.py --dataset sider --feature FP-Morgan --model_type scaffold --project SIDER_FP-Morgan_scaffold > SIDER_FP-Morgan_scaffold_.txt\n",
      "python Train_Property.py --dataset sider --feature FP-MACCS --model_type scaffold --project SIDER_FP-MACCS_scaffold > SIDER_FP-MACCS_scaffold_.txt\n",
      "python Train_Property.py --dataset sider --feature CNN --model_type scaffold --project SIDER_CNN_scaffold > SIDER_CNN_scaffold_.txt\n",
      "python Train_Property.py --dataset clintox --feature FP-Morgan --model_type scaffold --project CLINTOX_FP-Morgan_scaffold > CLINTOX_FP-Morgan_scaffold_.txt\n",
      "python Train_Property.py --dataset clintox --feature FP-MACCS --model_type scaffold --project CLINTOX_FP-MACCS_scaffold > CLINTOX_FP-MACCS_scaffold_.txt\n",
      "python Train_Property.py --dataset clintox --feature CNN --model_type scaffold --project CLINTOX_CNN_scaffold > CLINTOX_CNN_scaffold_.txt\n",
      "python Train_Property.py --dataset hiv --feature FP-Morgan --model_type scaffold --project HIV_FP-Morgan_scaffold > HIV_FP-Morgan_scaffold_.txt\n",
      "python Train_Property.py --dataset hiv --feature FP-MACCS --model_type scaffold --project HIV_FP-MACCS_scaffold > HIV_FP-MACCS_scaffold_.txt\n",
      "python Train_Property.py --dataset hiv --feature CNN --model_type scaffold --project HIV_CNN_scaffold > HIV_CNN_scaffold_.txt\n"
     ]
    }
   ],
   "source": [
    "name = 'scaffold'\n",
    "for dt in ['bace', 'bbbp', 'tox21', 'toxcast', 'sider', 'clintox', 'hiv']:\n",
    "    for ft in ['FP-Morgan', 'FP-MACCS', 'CNN']:\n",
    "        cmd = f\"python Train_Property.py --dataset {dt} --feature {ft} --project {dt.upper()}_{ft}_{name} > {dt.upper()}_{ft}_{name}_.txt\"\n",
    "        print(cmd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grapose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
