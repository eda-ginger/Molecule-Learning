{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rdkit\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem\n",
    "from deepchem.feat.smiles_tokenizer import BasicSmilesTokenizer\n",
    "from rdkit.Chem import Draw, AllChem, Descriptors, rdDepictor, rdDistGeom, MACCSkeys, rdMolDescriptors\n",
    "from rdkit.Chem import rdDepictor\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric import utils as pyg_utils\n",
    "from torch_geometric.data import InMemoryDataset, download_url, extract_gz, Data, DataLoader, Batch\n",
    "\n",
    "# # 작업을 위한 별도의 함수 불러오기\n",
    "# from utils.download_preprocess import CustomMoleculeNet, atom_features, EDGE_FEATURES\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(rdkit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARSMISET = {\"(\": 1, \".\": 2, \"0\": 3, \"2\": 4, \"4\": 5, \"6\": 6, \"8\": 7, \"@\": 8,\n",
    "                \"B\": 9, \"D\": 10, \"F\": 11, \"H\": 12, \"L\": 13, \"N\": 14, \"P\": 15, \"R\": 16,\n",
    "                \"T\": 17, \"V\": 18, \"Z\": 19, \"\\\\\": 20, \"b\": 21, \"d\": 22, \"f\": 23, \"h\": 24,\n",
    "                \"l\": 25, \"n\": 26, \"r\": 27, \"t\": 28, \"#\": 29, \"%\": 30, \")\": 31, \"+\": 32,\n",
    "                \"-\": 33, \"/\": 34, \"1\": 35, \"3\": 36, \"5\": 37, \"7\": 38, \"9\": 39, \"=\": 40,\n",
    "                \"A\": 41, \"C\": 42, \"E\": 43, \"G\": 44, \"I\": 45, \"K\": 46, \"M\": 47, \"O\": 48,\n",
    "                \"S\": 49, \"U\": 50, \"W\": 51, \"Y\": 52, \"[\": 53, \"]\": 54, \"a\": 55, \"c\": 56,\n",
    "                \"e\": 57, \"g\": 58, \"i\": 59, \"m\": 60, \"o\": 61, \"s\": 62, \"u\": 63, \"y\": 64, '~': 65} # add ~: 65 \n",
    "\n",
    "CHARISOSMILEN = 65\n",
    "\n",
    "CHARPROTSET = {\"A\": 1, \"C\": 2, \"B\": 3, \"E\": 4, \"D\": 5, \"G\": 6,\n",
    "               \"F\": 7, \"I\": 8, \"H\": 9, \"K\": 10, \"M\": 11, \"L\": 12,\n",
    "               \"O\": 13, \"N\": 14, \"Q\": 15, \"P\": 16, \"S\": 17, \"R\": 18,\n",
    "               \"U\": 19, \"T\": 20, \"W\": 21, \"V\": 22, \"Y\": 23, \"X\": 24, \"Z\": 25}\n",
    "\n",
    "CHARPROTLEN = 25\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "########## Function\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "def integer_label_encoding(sequence, tp, max_length=100):\n",
    "    \"\"\"\n",
    "    Integer encoding for string sequence.\n",
    "    Args:\n",
    "        sequence (str): Drug or Protein string sequence.\n",
    "        max_length: Maximum encoding length of input string.\n",
    "    \"\"\"\n",
    "    if tp == 'drug':\n",
    "        charset = CHARSMISET\n",
    "    elif tp == 'protein':\n",
    "        charset = CHARPROTSET\n",
    "\n",
    "    encoding = np.zeros(max_length)\n",
    "    for idx, letter in enumerate(sequence[:max_length]):\n",
    "        try:\n",
    "            if tp == 'protein':\n",
    "                letter = letter.upper()\n",
    "            letter = str(letter)\n",
    "            encoding[idx] = charset[letter]\n",
    "        except KeyError:\n",
    "            print(\n",
    "                f\"character {letter} does not exists in sequence category encoding, skip and treat as padding.\"\n",
    "            )\n",
    "    return Data(x=torch.from_numpy(encoding).to(torch.long).unsqueeze(dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_coord(smiles):\n",
    "    try:\n",
    "        # SMILES → Mol\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            print(f\"[Warning] MolFromSmiles failed for: {smiles}\")\n",
    "            return None\n",
    "        \n",
    "        mol = Chem.AddHs(mol)\n",
    "\n",
    "        # 3D 좌표 생성\n",
    "        status = AllChem.EmbedMolecule(mol, randomSeed=42)\n",
    "        if status != 0:\n",
    "            print(f\"[Warning] EmbedMolecule failed for: {smiles}\")\n",
    "            return None\n",
    "        \n",
    "        # 에너지 최소화\n",
    "        AllChem.UFFOptimizeMolecule(mol)\n",
    "\n",
    "        # conformer 가져오기\n",
    "        if mol.GetNumConformers() == 0:\n",
    "            print(f\"[Warning] No conformer generated for: {smiles}\")\n",
    "            return None\n",
    "        conf = mol.GetConformer()\n",
    "\n",
    "        # 원자 번호와 좌표 추출\n",
    "        z = []\n",
    "        pos = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            z.append(atom.GetAtomicNum())\n",
    "            p = conf.GetAtomPosition(atom.GetIdx())\n",
    "            pos.append([p.x, p.y, p.z])\n",
    "        \n",
    "        z = torch.tensor(z, dtype=torch.long)\n",
    "        pos = torch.tensor(pos, dtype=torch.float)\n",
    "        return Data(z=z, pos=pos)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Exception] Failed for {smiles}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "from pathlib import Path\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "RDLogger.DisableLog('rdApp.*')  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "# Updated transform_mol function with progress logging\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "from utils.molecule_feature import *\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def transform_mol(molecule_smiles, labels, choice):\n",
    "    mols = [Chem.MolFromSmiles(mol) for mol in molecule_smiles if mol]\n",
    "    print(f\"Processing {len(molecule_smiles)} molecules with {choice} transformation...\")\n",
    "    \n",
    "    # string tokenization\n",
    "    if choice == 'string_tokenization': # vocab dictionary, encoded smiles를 출력\n",
    "        print(\"Building vocabulary from SMILES tokens...\")\n",
    "        vocab = []\n",
    "        max_len = 0\n",
    "        tokenizer = BasicSmilesTokenizer()\n",
    "        for smi in tqdm(molecule_smiles, desc=\"Tokenizing SMILES\"):\n",
    "            tokens = tokenizer.tokenize(smi)\n",
    "            max_len = max(max_len, len(tokens))\n",
    "            vocab += tokens\n",
    "            \n",
    "        uniq_vocab = sorted(set(vocab))\n",
    "        smiles_vocab = {v: i for i, v in enumerate(uniq_vocab)}\n",
    "        smiles_vocab['Unk'] = len(smiles_vocab)\n",
    "        print(f\"Vocabulary size: {len(smiles_vocab)}\")\n",
    "        \n",
    "        print(\"Encoding SMILES sequences...\")\n",
    "        encoded_smiles = [[smiles_vocab.get(token, smiles_vocab['Unk']) for token in tokenizer.tokenize(smi)] for smi in tqdm(molecule_smiles, desc=\"Encoding SMILES\")]\n",
    "        smiles_vec = []\n",
    "        for vec, l, smi in tqdm(zip(encoded_smiles, labels, molecule_smiles), desc=\"Creating Data objects\", total=len(molecule_smiles)):\n",
    "            pad_len = max_len - len(vec)\n",
    "            vec = vec + ([0] * pad_len)\n",
    "            smiles_vec.append(Data(x=torch.tensor(vec).view(1, -1), y=torch.tensor([l], dtype=torch.float).view(1, -1), smiles=smi))\n",
    "        print(f\"Completed string tokenization for {len(smiles_vec)} molecules\")\n",
    "        return smiles_vocab, smiles_vec\n",
    "\n",
    "    # integer encoding (CNN)\n",
    "    elif choice == 'integer_encoding':\n",
    "        print(\"Converting SMILES to integer encoding...\")\n",
    "        integer_encoding_data = []\n",
    "        for smi, l in tqdm(zip(molecule_smiles, labels), desc=\"Integer encoding\", total=len(molecule_smiles)):\n",
    "             drug = integer_label_encoding(smi, 'drug')\n",
    "             drug.y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "             integer_encoding_data.append(drug)\n",
    "        print(f\"Completed integer encoding for {len(integer_encoding_data)} molecules\")\n",
    "        return integer_encoding_data\n",
    "\n",
    "    # 2D Graph\n",
    "    elif choice == '2D_graph':\n",
    "        print(\"Converting SMILES to 2D molecular graphs...\")\n",
    "        graph_data = [smiles_to_feature(smi) for smi in tqdm(molecule_smiles, desc=\"Creating 2D graphs\")]\n",
    "\n",
    "        graph_2d = []\n",
    "        for g, l, smi in tqdm(zip(graph_data, labels, molecule_smiles), desc=\"Adding labels to graphs\", total=len(molecule_smiles)):\n",
    "            g.y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "            g.smiles = smi\n",
    "            graph_2d.append(g)\n",
    "        print(f\"Completed 2D graph conversion for {len(graph_2d)} molecules\")\n",
    "        return graph_2d\n",
    "\n",
    "    # 3D Graph\n",
    "    elif choice == '3D_graph':\n",
    "        print(\"Converting SMILES to 3D molecular graphs...\")\n",
    "        graph_3d = []\n",
    "        for smi, l in tqdm(zip(molecule_smiles, labels), desc=\"Creating 3D graphs\", total=len(molecule_smiles)):\n",
    "            graph_data = smiles_to_coord(smi)\n",
    "            if graph_data is None:\n",
    "                print(f\"Failed to create 3D graph for {smi}\")\n",
    "                continue\n",
    "            graph_data.y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "            graph_3d.append(graph_data)\n",
    "        print(f\"Completed 3D graph conversion for {len(graph_3d)} molecules\")\n",
    "        return graph_3d\n",
    "\n",
    "    # ChemBERTa\n",
    "    elif choice == 'chemberta':\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"DeepChem/ChemBERTa-77M-MLM\")\n",
    "        model = AutoModel.from_pretrained(\"DeepChem/ChemBERTa-77M-MLM\")\n",
    "        print(\"Converting SMILES to ChemBERTa embeddings...\")\n",
    "        chemberta_data = []\n",
    "        for smi, l in tqdm(zip(molecule_smiles, labels), desc=\"Creating ChemBERTa embeddings\", total=len(molecule_smiles)):\n",
    "            with torch.no_grad():\n",
    "                inputs = tokenizer(smi, return_tensors='pt', padding=True, truncation=True)\n",
    "                outputs = model(**inputs)\n",
    "                embedding = outputs.last_hidden_state[:, 0, :].squeeze(0)  # (hidden_size,)\n",
    "            data = Data(x=embedding.unsqueeze(0), smiles=smi)\n",
    "            data.y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "            chemberta_data.append(data)\n",
    "        print(f\"Completed ChemBERTa embedding conversion for {len(chemberta_data)} molecules\")\n",
    "        return chemberta_data\n",
    "    \n",
    "    # Fingerprint\n",
    "    elif 'fingerprint' in choice:\n",
    "        print(f\"Generating {choice} fingerprints...\")\n",
    "        if choice == 'rdkit_fingerprint':\n",
    "            fp = [Chem.RDKFingerprint(mol) for mol in tqdm(mols, desc=\"RDKit fingerprints\")]\n",
    "        \n",
    "        elif choice == 'maccs_fingerprint':\n",
    "            fp = [MACCSkeys.GenMACCSKeys(mol) for mol in tqdm(mols, desc=\"MACCS fingerprints\")]\n",
    "        \n",
    "        elif choice == 'morgan_fingerprint':\n",
    "            fp = [AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024) for mol in tqdm(mols, desc=\"Morgan fingerprints\")]\n",
    "\n",
    "        print(\"Converting fingerprints to Data objects...\")\n",
    "        fps = [Data(x=torch.tensor(f).view(1, -1), y=torch.tensor([l], dtype=torch.float).view(1, -1), smiles=smi) for f, l, smi in tqdm(zip(fp, labels, molecule_smiles), desc=\"Creating fingerprint Data objects\", total=len(molecule_smiles))]\n",
    "        print(f\"Completed {choice} generation for {len(fps)} molecules\")\n",
    "        return fps\n",
    "\n",
    "    # Descriptors\n",
    "    elif choice == 'descriptors':\n",
    "        print(\"Calculating molecular descriptors...\")\n",
    "        # 모델 학습을 위해서는 스케일링 작업이 별도로 필요하다는 것을 기억하자!\n",
    "        desc = []\n",
    "        for mol, l, smi in tqdm(zip(mols, labels, molecule_smiles), desc=\"Calculating descriptors\", total=len(molecule_smiles)):\n",
    "            x = torch.tensor(list(Descriptors.CalcMolDescriptors(mol).values()), dtype=torch.float).view(1, -1)\n",
    "            y = torch.tensor([l], dtype=torch.float).view(1, -1)\n",
    "            desc.append(Data(x=x, y=y, smiles=smi))\n",
    "        print(f\"Completed descriptor calculation for {len(desc)} molecules\")\n",
    "        return desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dta_trn = pd.read_csv('dta_dataset/davis/train.csv')\n",
    "dta_val = pd.read_csv('dta_dataset/davis/valid.csv')\n",
    "dta_tst = pd.read_csv('dta_dataset/davis/test.csv')\n",
    "\n",
    "dta_trn['Set'] = 'TRN'\n",
    "dta_val['Set'] = 'VAL'\n",
    "dta_tst['Set'] = 'TST'\n",
    "\n",
    "dta = pd.concat([dta_trn, dta_val, dta_tst]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta['CNN'] = transform_mol(dta['Drug'], dta['Y'], 'integer_encoding')\n",
    "dta['2D-GNN'] = transform_mol(dta['Drug'], dta['Y'], '2D_graph')\n",
    "dta['FP-Morgan'] = transform_mol(dta['Drug'], dta['Y'], 'morgan_fingerprint') # 1024\n",
    "dta['FP-MACCS'] = transform_mol(dta['Drug'], dta['Y'], 'maccs_fingerprint') # 167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta['3D-GNN'] = transform_mol(dta['Drug'], dta['Y'], '3D_graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta['ChemBERTa'] = transform_mol(dta['Drug'], dta['Y'], 'chemberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_mol(dta['Drug'][:10], dta['Y'][:10], 'chemberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta['Target_Rep'] = dta['Target'].apply(lambda x: integer_label_encoding(x, 'protein', 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "fd = Path('dta_dataset/davis/feature/')\n",
    "fd.mkdir(parents=True, exist_ok=True)\n",
    "# for ft in ['CNN', '2D-GNN', 'FP-Morgan', 'FP-MACCS']:\n",
    "# for ft in ['3D-GNN', 'ChemBERTa']:\n",
    "for ft in ['ChemBERTa']:\n",
    "    nfd = fd / ft\n",
    "    nfd.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    trn_sub = dta[dta['Set'] == 'TRN'][[ft, 'Target_Rep']].reset_index(drop=True).rename(columns={ft: 'Drug_Rep'}).to_dict('records')\n",
    "    val_sub = dta[dta['Set'] == 'VAL'][[ft, 'Target_Rep']].reset_index(drop=True).rename(columns={ft: 'Drug_Rep'}).to_dict('records')\n",
    "    tst_sub = dta[dta['Set'] == 'TST'][[ft, 'Target_Rep']].reset_index(drop=True).rename(columns={ft: 'Drug_Rep'}).to_dict('records')\n",
    "    # print(f'{ft} feature_dim', dta[ft].values[0].x.shape)\n",
    "    \n",
    "    with open(nfd / 'trn.pkl', 'wb') as f:\n",
    "        pickle.dump(trn_sub, f)\n",
    "    with open(nfd / 'val.pkl', 'wb') as f:\n",
    "        pickle.dump(val_sub, f)\n",
    "    with open(nfd / 'tst.pkl', 'wb') as f:\n",
    "        pickle.dump(tst_sub, f)\n",
    "    \n",
    "    print('Saved', nfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc = pd.read_csv('data/zinc/zinc15_250K.csv')\n",
    "zinc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform_mol_nolabel(molecule_smiles, choice):\n",
    "#     mols = [Chem.MolFromSmiles(mol) for mol in molecule_smiles if mol]\n",
    "#     print(f\"Processing {len(molecule_smiles)} molecules with {choice} transformation...\")\n",
    "    \n",
    "#      # integer encoding (CNN)\n",
    "#     if choice == 'integer_encoding':\n",
    "#         print(\"Converting SMILES to integer encoding...\")\n",
    "#         integer_encoding_data = {}\n",
    "#         for smi in tqdm(molecule_smiles):\n",
    "#              drug = integer_label_encoding(smi, 'drug')\n",
    "#              integer_encoding_data[smi] = drug\n",
    "#         print(f\"Completed integer encoding for {len(integer_encoding_data)} molecules\")\n",
    "#         return integer_encoding_data\n",
    "\n",
    "#     # 2D Graph\n",
    "#     elif choice == '2D_graph':\n",
    "#         print(\"Converting SMILES to 2D molecular graphs...\")\n",
    "#         graph_data = {smi: drug_to_graph(smi) for smi in tqdm(molecule_smiles, desc=\"Creating 2D graphs\")}\n",
    "#         print(f\"Completed 2D graph conversion for {len(graph_data)} molecules\")\n",
    "#         return graph_data\n",
    "\n",
    "#     # 3D Graph\n",
    "#     elif choice == '3D_graph':\n",
    "#         print(\"Converting SMILES to 3D molecular graphs...\")\n",
    "#         graph_3d = {}\n",
    "#         for smi in tqdm(molecule_smiles):\n",
    "#             graph_data = drug_to_graph(smi)\n",
    "            \n",
    "#             mol = Chem.MolFromSmiles(smi)\n",
    "#             atom_info = [(atom.GetIdx(), atom.GetSymbol()) for atom in mol.GetAtoms()]\n",
    "                     \n",
    "#             mol = AllChem.AddHs(mol, addCoords=True)\n",
    "#             emb_mol = rdDistGeom.EmbedMolecule(mol)\n",
    "#             if emb_mol == -1:\n",
    "#                 rdDepictor.Compute2DCoords(mol)\n",
    "\n",
    "#             conf = mol.GetConformer()\n",
    "#             pos = np.array([conf.GetAtomPosition(idx) for idx, symbol in atom_info])\n",
    "#             graph_data.pos = pos\n",
    "#             graph_3d[smi] = graph_data\n",
    "#         print(f\"Completed 3D graph conversion for {len(graph_3d)} molecules\")\n",
    "#         return graph_3d\n",
    "    \n",
    "#     # Fingerprint\n",
    "#     elif 'fingerprint' in choice:\n",
    "#         print(f\"Generating {choice} fingerprints...\")\n",
    "#         if choice == 'rdkit_fingerprint':\n",
    "#             fp = [Chem.RDKFingerprint(mol) for mol in tqdm(mols, desc=\"RDKit fingerprints\")]\n",
    "        \n",
    "#         elif choice == 'maccs_fingerprint':\n",
    "#             fp = [MACCSkeys.GenMACCSKeys(mol) for mol in tqdm(mols, desc=\"MACCS fingerprints\")]\n",
    "        \n",
    "#         elif choice == 'morgan_fingerprint':\n",
    "#             fp = [AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024) for mol in tqdm(mols, desc=\"Morgan fingerprints\")]\n",
    "\n",
    "#         print(\"Converting fingerprints to Data objects...\")\n",
    "#         fps = {smi: Data(x=torch.tensor(f).view(1, -1)) for f, smi in tqdm(zip(fp, molecule_smiles), desc=\"Creating fingerprint Data objects\")}\n",
    "#         print(f\"Completed {choice} generation for {len(fps)} molecules\")\n",
    "#         return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '20250628'\n",
    "# for dt in ['bace', 'bbbp', 'tox21', 'toxcast', 'sider', 'clintox', 'hiv']:\n",
    "for dt in ['tox21', 'hiv']:\n",
    "    for ft in ['ChemBERTa']:\n",
    "        cmd = f\"python Train_Property.py --dataset {dt} --feature {ft} --filename {name} --project {dt.upper()}_{ft}_{name}  > ./logs/new/{dt}_{ft}.txt\"\n",
    "        print(cmd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '20250630'\n",
    "for dt in ['bace', 'bbbp', 'tox21', 'toxcast', 'sider', 'clintox', 'hiv']:\n",
    "    for ft in ['2D-GNN', '2D-GNN-tuto', 'CNN', 'FP-MACCS', 'FP-Morgan', '3D-GNN', 'ChemBERTa']:\n",
    "        cmd = f\"python Train_Property.py --dataset {dt} --feature {ft} --filename {name} --project {dt.upper()}_{ft}_{name}  > ./logs/new2/{dt}_{ft}.txt\"\n",
    "        print(cmd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.loader import MoleculeDataset ##\n",
    "data_root = \"dataset/\"\n",
    "feature= '2D-GNN'\n",
    "\n",
    "dataset = MoleculeDataset(data_root + 'bace', dataset='bace', feature=feature)\n",
    "dataset = MoleculeDataset(data_root + 'bbbp', dataset='bbbp', feature=feature)\n",
    "dataset = MoleculeDataset(data_root + 'tox21', dataset='tox21', feature=feature)\n",
    "dataset = MoleculeDataset(data_root + 'toxcast', dataset='toxcast', feature=feature)\n",
    "dataset = MoleculeDataset(data_root + 'sider', dataset='sider', feature=feature)\n",
    "dataset = MoleculeDataset(data_root + 'clintox', dataset='clintox', feature=feature)\n",
    "dataset = MoleculeDataset(data_root + 'hiv', dataset='hiv', feature=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt_name in ['bace', 'bbbp', 'tox21', 'toxcast', 'sider', 'clintox', 'hiv']:\n",
    "    print(dt_name)\n",
    "    dt1 = MoleculeDataset(data_root + dt_name, dataset=dt_name, feature='2D-GNN')\n",
    "    dt2 = MoleculeDataset(data_root + dt_name, dataset=dt_name, feature='3D-GNN')\n",
    "    check = set(dt1.smiles) & set(dt2.smiles)\n",
    "    print(len(dt1.smiles), len(dt2.smiles), len(check))\n",
    "    if len(check) != len(dt1.smiles):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.loader import MoleculeDataset ##\n",
    "data_root = \"dataset/\"\n",
    "for feature in ['2D-GNN-tuto', 'CNN', 'FP-MACCS', 'FP-Morgan', 'ChemBERTa']:\n",
    "    dataset = MoleculeDataset(data_root + 'bace', dataset='bace', feature=feature)\n",
    "    dataset = MoleculeDataset(data_root + 'bbbp', dataset='bbbp', feature=feature)\n",
    "    dataset = MoleculeDataset(data_root + 'tox21', dataset='tox21', feature=feature)\n",
    "    dataset = MoleculeDataset(data_root + 'toxcast', dataset='toxcast', feature=feature)\n",
    "    dataset = MoleculeDataset(data_root + 'sider', dataset='sider', feature=feature)\n",
    "    dataset = MoleculeDataset(data_root + 'clintox', dataset='clintox', feature=feature)\n",
    "    dataset = MoleculeDataset(data_root + 'hiv', dataset='hiv', feature=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.loader import MoleculeDataset ##\n",
    "data_root = \"dataset/\"\n",
    "for feature in ['2D-GNN-tuto', 'CNN', 'FP-MACCS', 'FP-Morgan', 'ChemBERTa']:\n",
    "    print(feature)\n",
    "    print(MoleculeDataset(data_root + 'bace', dataset='bace', feature=feature))\n",
    "    print(MoleculeDataset(data_root + 'bbbp', dataset='bbbp', feature=feature))\n",
    "    print(MoleculeDataset(data_root + 'tox21', dataset='tox21', feature=feature))\n",
    "    print(MoleculeDataset(data_root + 'toxcast', dataset='toxcast', feature=feature))\n",
    "    print(MoleculeDataset(data_root + 'sider', dataset='sider', feature=feature))\n",
    "    print(MoleculeDataset(data_root + 'clintox', dataset='clintox', feature=feature))\n",
    "    print(MoleculeDataset(data_root + 'hiv', dataset='hiv', feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.loader import MoleculeDataset ##\n",
    "data_root = \"dataset/\"\n",
    "for dt_name in ['bace', 'bbbp', 'tox21', 'toxcast', 'sider', 'clintox', 'hiv']:\n",
    "    dataset_base = MoleculeDataset(data_root + dt_name, dataset=dt_name, feature='2D-GNN')\n",
    "    dataset_3d = MoleculeDataset(data_root + dt_name, dataset=dt_name, feature='3D-GNN')\n",
    "\n",
    "    base_smi = '\\n'.join(str(i) for i in dataset_base.smiles)\n",
    "    with open(f'dataset/{dt_name}/processed/base_smi.txt', 'w') as f:\n",
    "        f.write(f'base_smi: {len(dataset_base.smiles)}\\n')\n",
    "        f.write(base_smi)\n",
    "\n",
    "    smi_3d = set(dataset_base.smiles) & set(dataset_3d.smiles)\n",
    "    smi_3d_file = '\\n'.join(str(i) for i in smi_3d)\n",
    "    with open(f'dataset/{dt_name}/processed/3d_smi.txt', 'w') as f:\n",
    "        f.write(f'3d_smi: {len(smi_3d)}\\n')\n",
    "        f.write(smi_3d_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.loader import MoleculeDataset ##\n",
    "data_root = \"dataset/\"\n",
    "# for feature in ['3D-GNN']:\n",
    "for feature in ['2D-GNN', '2D-GNN-tuto', 'CNN', '3D-GNN','FP-MACCS', 'FP-Morgan', 'ChemBERTa']:\n",
    "    print(feature)\n",
    "    dataset = MoleculeDataset(data_root + 'esol', dataset='esol', feature=feature)\n",
    "    dataset = MoleculeDataset(data_root + 'freesolv', dataset='freesolv', feature=feature)\n",
    "    dataset = MoleculeDataset(data_root + 'lipophilicity', dataset='lipophilicity', feature=feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '20250630'\n",
    "for dt in ['freesolv', 'esol', 'lipophilicity']:\n",
    "    for ft in ['2D-GNN', '2D-GNN-tuto', 'CNN', 'FP-MACCS', 'FP-Morgan', '3D-GNN', 'ChemBERTa']:\n",
    "        cmd = f\"python Train_Property.py --dataset {dt} --feature {ft} --filename {name} --project {dt.upper()}_{ft}_{name}  > ./logs/new2/{dt}_{ft}.txt\"\n",
    "        print(cmd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.loader import MoleculeDataset ##\n",
    "data_root = \"dataset/\"\n",
    "for dt_name in ['freesolv', 'esol', 'lipophilicity']:\n",
    "    dataset_base = MoleculeDataset(data_root + dt_name, dataset=dt_name, feature='2D-GNN')\n",
    "    dataset_3d = MoleculeDataset(data_root + dt_name, dataset=dt_name, feature='3D-GNN')\n",
    "\n",
    "    base_smi = '\\n'.join(str(i) for i in dataset_base.smiles)\n",
    "    with open(f'dataset/{dt_name}/processed/base_smi.txt', 'w') as f:\n",
    "        f.write(f'base_smi: {len(dataset_base.smiles)}\\n')\n",
    "        f.write(base_smi)\n",
    "\n",
    "    smi_3d = set(dataset_base.smiles) & set(dataset_3d.smiles)\n",
    "    smi_3d_file = '\\n'.join(str(i) for i in smi_3d)\n",
    "    with open(f'dataset/{dt_name}/processed/3d_smi.txt', 'w') as f:\n",
    "        f.write(f'3d_smi: {len(smi_3d)}\\n')\n",
    "        f.write(smi_3d_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
